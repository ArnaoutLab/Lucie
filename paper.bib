
@misc{offord2023,
	title = {{UK} {Biobank} releases half a million whole-genome sequences for biomedical research},
	url = {https://www.science.org/content/article/uk-biobank-releases-half-million-whole-genome-sequences-biomedical-research},
	abstract = {The release more than doubles the size of an earlier data set and will help reveal new links between DNA, health, and disease, geneticists say},
	language = {en},
	urldate = {2024-10-08},
	journal = {ScienceInsider},
	author = {Offord, Catherine},
	month = nov,
	year = {2023},
	file = {Snapshot:/Users/ramy/Zotero/storage/L4RJZGQD/uk-biobank-releases-half-million-whole-genome-sequences-biomedical-research.html:text/html},
}


@article{openscience2023,
	title = {Open science},
	volume = {33},
	issn = {1879-0445},
	doi = {10.1016/j.cub.2023.05.036},
	abstract = {The term 'open science' refers to a range of methods, tools, platforms and practices that aim to make scientific research more accessible, transparent, reproducible and reliable. This includes, for example, sharing code, data and research materials, embracing new publishing formats such as registered reports and preprints, pursuing replication studies and reanalyses, optimising statistical approaches to improve evidence assessment and re-evaluating institutional incentives. The ongoing shift towards open science practices is partly due to mounting evidence that studies across disciplines suffer from biases, underpowered designs and irreproducible or non-replicable results. It also stems from a general desire amongst many researchers to reduce hyper-competitivity in science and instead promote collaborative research that benefits science and society.},
	language = {eng},
	number = {15},
	journal = {Current biology: CB},
	author = {Bertram, Michael G. and Sundin, Josefin and Roche, Dominique G. and Sánchez-Tójar, Alfredo and Thoré, Eli S. J. and Brodin, Tomas},
	month = aug,
	year = {2023},
	pmid = {37552940},
	keywords = {Humans, Motivation, Publishing, Research Personnel},
	pages = {R792--R797},
	file = {Full Text:/Users/ramy/Zotero/storage/RXQP8DU9/Bertram et al. - 2023 - Open science.pdf:application/pdf},
}


@article{lakhani2013,
	title = {Prize-based contests can provide solutions to computational biology problems},
	volume = {31},
	issn = {1087-0156, 1546-1696},
	url = {http://www.nature.com/articles/nbt.2495},
	doi = {10.1038/nbt.2495},
	language = {en},
	number = {2},
	urldate = {2022-08-20},
	journal = {Nature Biotechnology},
	author = {Lakhani, Karim R and Boudreau, Kevin J and Loh, Po-Ru and Backstrom, Lars and Baldwin, Carliss and Lonstein, Eric and Lydon, Mike and MacCormack, Alan and Arnaout, Ramy A and Guinan, Eva C},
	month = feb,
	year = {2013},
	pages = {108--111},
	annote = {Lakhani, Karim RBoudreau, Kevin JLoh, Po-RuBackstrom, LarsBaldwin, CarlissLonstein, EricLydon, MikeMacCormack, AlanArnaout, Ramy AGuinan, Eva C5UL1RR025758/RR/NCRR NIH HHS/United States5UL1RR025758-S/RR/NCRR NIH HHS/United StatesLetterResearch Support, N.I.H., ExtramuralResearch Support, Non-U.S. Gov'tResearch Support, U.S. Gov't, Non-P.H.S.United StatesNature biotechnologyNat Biotechnol. 2013 Feb;31(2):108-11. doi: 10.1038/nbt.2495.},
	annote = {Lakhani, Karim RBoudreau, Kevin JLoh, Po-RuBackstrom, LarsBaldwin, CarlissLonstein, EricLydon, MikeMacCormack, AlanArnaout, Ramy AGuinan, Eva C5UL1RR025758/RR/NCRR NIH HHS/United States5UL1RR025758-S/RR/NCRR NIH HHS/United StatesLetterResearch Support, N.I.H., ExtramuralResearch Support, Non-U.S. Gov'tResearch Support, U.S. Gov't, Non-P.H.S.United StatesNature biotechnologyNat Biotechnol. 2013 Feb;31(2):108-11. doi: 10.1038/nbt.2495.},
	annote = {Lakhani, Karim RBoudreau, Kevin JLoh, Po-RuBackstrom, LarsBaldwin, CarlissLonstein, EricLydon, MikeMacCormack, AlanArnaout, Ramy AGuinan, Eva C5UL1RR025758/RR/NCRR NIH HHS/United States5UL1RR025758-S/RR/NCRR NIH HHS/United StatesLetterResearch Support, N.I.H., ExtramuralResearch Support, Non-U.S. Gov'tResearch Support, U.S. Gov't, Non-P.H.S.United StatesNature biotechnologyNat Biotechnol. 2013 Feb;31(2):108-11. doi: 10.1038/nbt.2495.},
	annote = {Lakhani, Karim RBoudreau, Kevin JLoh, Po-RuBackstrom, LarsBaldwin, CarlissLonstein, EricLydon, MikeMacCormack, AlanArnaout, Ramy AGuinan, Eva C5UL1RR025758/RR/NCRR NIH HHS/United States5UL1RR025758-S/RR/NCRR NIH HHS/United StatesLetterResearch Support, N.I.H., ExtramuralResearch Support, Non-U.S. Gov'tResearch Support, U.S. Gov't, Non-P.H.S.United StatesNature biotechnologyNat Biotechnol. 2013 Feb;31(2):108-11. doi: 10.1038/nbt.2495.},
	file = {Lakhani et al. - 2013 - Prize-based contests can provide solutions to comp.pdf:/Users/ramy/Zotero/storage/2NQC289B/Lakhani et al. - 2013 - Prize-based contests can provide solutions to comp.pdf:application/pdf},
}

@article{cooperation2021,
	title = {Cooperation under {Pressure}: {Lessons} from the {COVID}-19 {Swab} {Crisis}},
	volume = {59},
	issn = {1098-660X},
	shorttitle = {Cooperation under {Pressure}},
	url = {https://pubmed.ncbi.nlm.nih.gov/34406796/},
	doi = {10.1128/JCM.01239-21},
	abstract = {The early months of the COVID-19 pandemic were marked by a desperate need for nasopharyngeal swabs to test for SARS-CoV-2, with demand far outstripping supply. April marked the anniversary of an unprecedented nationwide multibusiness/multihospital partnership that successfully met this need, a fitti …},
	language = {en},
	number = {10},
	urldate = {2024-10-05},
	journal = {Journal of clinical microbiology},
	author = {Arnaout, R},
	month = sep,
	year = {2021},
	pmid = {34406796},
	note = {Publisher: J Clin Microbiol},
	file = {Full Text:/Users/ramy/Zotero/storage/73KPXM6B/Ra - 2021 - Cooperation under Pressure Lessons from the COVID-19 Swab Crisis.pdf:application/pdf;Snapshot:/Users/ramy/Zotero/storage/7EX34PHW/34406796.html:text/html},
}

@misc{swab2020,
	title = {Open {Development} and {Clinical} {Validation} {Of} {Multiple} {3D}-{Printed} {Sample}-{Collection} {Swabs}: {Rapid} {Resolution} of a {Critical} {COVID}-19 {Testing} {Bottleneck}},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	shorttitle = {Open {Development} and {Clinical} {Validation} {Of} {Multiple} {3D}-{Printed} {Sample}-{Collection} {Swabs}},
	url = {https://www.medrxiv.org/content/10.1101/2020.04.14.20065094v2},
	doi = {10.1101/2020.04.14.20065094},
	abstract = {The SARS-CoV-2 pandemic has caused a severe international shortage of the nasopharyngeal swabs that are required for collection of optimal specimens, creating a critical bottleneck in the way of high-sensitivity virological testing for COVID-19. To address this crisis, we designed and executed an innovative, radically cooperative, rapid-response translational-research program that brought together healthcare workers, manufacturers, and scientists to emergently develop and clinically validate new swabs for immediate mass production by 3D printing. We performed a rigorous multi-step preclinical evaluation on 160 swab designs and 48 materials from 24 companies, laboratories, and individuals, and shared results and other feedback via a public data repository (http://github.com/rarnaout/Covidswab/). We validated four prototypes through an institutional review board (IRB)-approved clinical trial that involved 276 outpatient volunteers who presented to our hospital’s drive-through testing center with symptoms suspicious for COVID-19. Each participant was swabbed with a reference swab (the control) and a prototype, and SARS-CoV-2 reverse-transcriptase polymerase chain reaction (RT-PCR) results were compared. All prototypes displayed excellent concordance with the control (κ=0.85-0.89). Cycle-threshold (Ct) values were not significantly different between each prototype and the control, supporting the new swabs’ non-inferiority (Mann-Whitney U [MWU] p{\textgreater}0.05). Study staff preferred one of the prototypes over the others and the control swab overall. The total time elapsed between identification of the problem and validation of the first prototype was 22 days. Contact information for ordering can be found at http://printedswabs.org. Our experience holds lessons for the rapid development, validation, and deployment of new technology for this pandemic and beyond.},
	language = {en},
	urldate = {2024-10-05},
	publisher = {medRxiv},
	author = {Callahan, Cody J. and Lee, Rose and Zulauf, Katelyn E. and Tamburello, Lauren and Smith, Kenneth P. and Previtera, Joe and Cheng, Annie and Green, Alex and Azim, Ahmed Abdul and Yano, Amanda and Doraiswami, Nancy and Kirby, James E. and Arnaout, Ramy A.},
	month = may,
	year = {2020},
	note = {ISSN: 2006-5094
Pages: 2020.04.14.20065094},
	file = {Full Text PDF:/Users/ramy/Zotero/storage/LMLRVUY8/Callahan et al. - 2020 - Open Development and Clinical Validation Of Multiple 3D-Printed Sample-Collection Swabs Rapid Resol.pdf:application/pdf},
}

@article{omicron2022,
	title = {Visualizing omicron: {COVID}-19 deaths vs. cases over time},
	volume = {17},
	issn = {1932-6203},
	shorttitle = {Visualizing omicron},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0265233},
	doi = {10.1371/journal.pone.0265233},
	abstract = {For most of the COVID-19 pandemic, the daily focus has been on the number of cases, and secondarily, deaths. The most recent wave was caused by the omicron variant, first identified at the end of 2021 and the dominant variant through the first part of 2022. South Africa, one of the first countries to experience and report data regarding omicron (variant 21.K), reported far fewer deaths, even as the number of reported cases rapidly eclipsed previous peaks. However, as the omicron wave has progressed, time series show that it has been markedly different from prior waves. To more readily visualize the dynamics of cases and deaths, it is natural to plot deaths per million against cases per million. Unlike the time-series plots of cases or deaths that have become daily features of pandemic updates during the pandemic, which have time as the x-axis, in a plot of deaths vs. cases, time is implicit, and is indicated in relation to the starting point. Here we present and briefly examine such plots from a number of countries and from the world as a whole, illustrating how they summarize features of the pandemic in ways that illustrate how, in most places, the omicron wave is very different from those that came before. Code for generating these plots for any country is provided in an automatically updating GitHub repository.},
	language = {en},
	number = {4},
	urldate = {2024-10-05},
	journal = {PLOS ONE},
	author = {Arnaout, Ramy and Arnaout, Rima},
	month = apr,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {COVID 19, Death rates, Denmark, Information retrieval, Israel, Pandemics, South Africa, Vaccination and immunization},
	pages = {e0265233},
	file = {Full Text PDF:/Users/ramy/Zotero/storage/24ZJHJT8/Arnaout and Arnaout - 2022 - Visualizing omicron COVID-19 deaths vs. cases over time.pdf:application/pdf},
}


@article{beautifulsoup,
	title = {Beautiful soup documentation},
	journal = {April},
	author = {Richardson, Leonard},
	year = {2007},
}

@misc{kaggle_diabetes,
	title = {{UCI} {Diabetes} {Data} {Set}},
	url = {https://www.kaggle.com/datasets/ealtintas/uci-machine-learning-repository-diabetes-data-set},
	abstract = {UCI Machine Learning Repository Diabetes Data Set},
	language = {en},
	urldate = {2024-10-03},
	file = {Snapshot:/Users/ramy/Zotero/storage/FY6IM8Y4/uci-machine-learning-repository-diabetes-data-set.html:text/html},
}

@misc{huggingface_reuters,
	title = {ucirvine/reuters21578 · {Datasets} at {Hugging} {Face}},
	url = {https://huggingface.co/datasets/ucirvine/reuters21578},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-10-03},
	month = sep,
	year = {2023},
	file = {Snapshot:/Users/ramy/Zotero/storage/G6YDNCG5/reuters21578.html:text/html},
}

@misc{github_movies,
	title = {cernoch/movies},
	url = {https://github.com/cernoch/movies},
	abstract = {Movie Data Set from UCI, cleaned up},
	urldate = {2024-10-03},
	author = {Černoch, Radomír},
	month = feb,
	year = {2023},
	note = {original-date: 2012-08-13T14:15:46Z},
}

@misc{reuters,
	title = {reuters-text-categorization/reuters\_loader.py at master · jchavando/reuters-text-categorization · {GitHub}},
	url = {https://github.com/jchavando/reuters-text-categorization/blob/master/reuters_loader.py},
	urldate = {2024-10-03},
	file = {reuters-text-categorization/reuters_loader.py at master · jchavando/reuters-text-categorization · GitHub:/Users/ramy/Zotero/storage/EIU67EMP/reuters_loader.html:text/html},
}


@misc{ucimlrepo2024,
	title = {uci-ml-repo/ucimlrepo},
	copyright = {MIT},
	url = {https://github.com/uci-ml-repo/ucimlrepo},
	abstract = {Python package for dataset imports from UCI ML Repository},
	urldate = {2024-10-03},
	publisher = {uci-ml-repo},
	month = sep,
	year = {2024},
	note = {original-date: 2023-07-24T22:43:57Z},
}


@misc{badr2019,
	title = {Top {Sources} {For} {Machine} {Learning} {Datasets}},
	url = {https://towardsdatascience.com/top-sources-for-machine-learning-datasets-bb6d0dc3378b},
	abstract = {Your Ultimate Guide For Finding Machine Learning Datasets},
	language = {en},
	urldate = {2024-10-03},
	journal = {Medium},
	author = {Badr, Will},
	month = jul,
	year = {2019},
	file = {Snapshot:/Users/ramy/Zotero/storage/82KZ8AAY/top-sources-for-machine-learning-datasets-bb6d0dc3378b.html:text/html},
}

@misc{uci2024,
	title = {The {UCI} machine learning repository},
	url = {https://archive.ics.uci.edu},
	publisher = {University of California, Irvine, School of Information and Computer Sciences},
	author = {Markelle Kelly, Rachel Longjohn, Kolby Nottingham},
	year = {2024},
}



@misc{couch2024,
      title={Beyond Size and Class Balance: Alpha as a New Dataset Quality Metric for Deep Learning}, 
      author={Josiah Couch and Rima Arnaout and Ramy Arnaout},
      year={2024},
      eprint={2407.15724},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.15724}, 
}

%%%%%%

@article{althnian2021,
	title = {Impact of {Dataset} {Size} on {Classification} {Performance}: {An} {Empirical} {Evaluation} in the {Medical} {Domain}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {Impact of {Dataset} {Size} on {Classification} {Performance}},
	url = {https://www.mdpi.com/2076-3417/11/2/796},
	doi = {10.3390/app11020796},
	abstract = {Dataset size is considered a major concern in the medical domain, where lack of data is a common occurrence. This study aims to investigate the impact of dataset size on the overall performance of supervised classification models. We examined the performance of six widely-used models in the medical field, including support vector machine (SVM), neural networks (NN), C4.5 decision tree (DT), random forest (RF), adaboost (AB), and naïve Bayes (NB) on eighteen small medical UCI datasets. We further implemented three dataset size reduction scenarios on two large datasets and analyze the performance of the models when trained on each resulting dataset with respect to accuracy, precision, recall, f-score, specificity, and area under the ROC curve (AUC). Our results indicated that the overall performance of classifiers depend on how much a dataset represents the original distribution rather than its size. Moreover, we found that the most robust model for limited medical data is AB and NB, followed by SVM, and then RF and NN, while the least robust model is DT. Furthermore, an interesting observation is that a robust machine learning model to limited dataset does not necessary imply that it provides the best performance compared to other models.},
	language = {en},
	number = {2},
	urldate = {2024-07-28},
	journal = {Applied Sciences},
	author = {Althnian, Alhanoof and AlSaeed, Duaa and Al-Baity, Heyam and Samha, Amani and Dris, Alanoud Bin and Alzakari, Najla and Abou Elwafa, Afnan and Kurdi, Heba},
	month = jan,
	year = {2021},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {classification, dataset size, machine learning, medical data, performance, supervised models},
	pages = {796},
	file = {applsci-11-00796:/Users/ramy/Zotero/storage/Y4PRQ6LP/applsci-11-00796.pdf:application/pdf;Full Text PDF:/Users/ramy/Zotero/storage/9CEQ2T6Y/Althnian et al. - 2021 - Impact of Dataset Size on Classification Performance An Empirical Evaluation in the Medical Domain.pdf:application/pdf},
}

@article{buda2018,
	title = {A systematic study of the class imbalance problem in convolutional neural networks},
	volume = {106},
	issn = {08936080},
	url = {http://arxiv.org/abs/1710.05381},
	doi = {10.1016/j.neunet.2018.07.011},
	abstract = {In this study, we systematically investigate the impact of class imbalance on classiﬁcation performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the eﬀects of imbalance on classiﬁcation and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable diﬃculties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the eﬀect of class imbalance on classiﬁcation performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overﬁtting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classiﬁed cases is of interest.},
	language = {en},
	urldate = {2024-07-25},
	journal = {Neural Networks},
	author = {Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A.},
	month = oct,
	year = {2018},
	note = {arXiv:1710.05381 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	pages = {249--259},
}


@article{jo2004,
	volume = {6},
	title = {Class imbalances versus small disjuncts},
	issn = {1931-0145, 1931-0153},
	url = {https://dl.acm.org/doi/10.1145/1007730.1007737},
	doi = {10.1145/1007730.1007737},
	abstract = {It is often assumed that class imbalances are responsible for significant losses of performance in standard classifiers. The purpose of this paper is to the question whether class imbalances are truly responsible for this degradation or whether it can be explained in some other way. Our experiments suggest that the problem is not directly caused by class imbalances, but rather, that class imbalances may yield small disjuncts which, in turn, will cause degradation. We argue that, in order to improve classifier performance, it may, then, be more useful to focus on the small disjuncts problem than it is to focus on the class imbalance problem. We experiment with a method that takes the small disjunct problem into consideration, and show that, indeed, it yields a performance superior to the performance obtained using standard or advanced solutions to the class imbalance problem.},
	language = {en},
	number = {1},
	urldate = {2024-07-25},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Jo, Taeho and Japkowicz, Nathalie},
	month = jun,
	year = {2004},
	pages = {40--49},
}


@article{guo2004,
	title = {Learning from imbalanced data sets with boosting and data generation: the {DataBoost}-{IM} approach},
	volume = {6},
	issn = {1931-0145},
	shorttitle = {Learning from imbalanced data sets with boosting and data generation},
	url = {https://doi.org/10.1145/1007730.1007736},
	doi = {10.1145/1007730.1007736},
	abstract = {Learning from imbalanced data sets, where the number of examples of one (majority) class is much higher than the others, presents an important challenge to the machine learning community. Traditional machine learning algorithms may be biased towards the majority class, thus producing poor predictive accuracy over the minority class. In this paper, we describe a new approach that combines boosting, an ensemble-based learning algorithm, with data generation to improve the predictive power of classifiers against imbalanced data sets consisting of two classes. In the DataBoost-IM method, hard examples from both the majority and minority classes are identified during execution of the boosting algorithm. Subsequently, the hard examples are used to separately generate synthetic examples for the majority and minority classes. The synthetic data are then added to the original training set, and the class distribution and the total weights of the different classes in the new training set are rebalanced. The DataBoost-IM method was evaluated, in terms of the F-measures, G-mean and overall accuracy, against seventeen highly and moderately imbalanced data sets using decision trees as base classifiers. Our results are promising and show that the DataBoost-IM method compares well in comparison with a base classifier, a standard benchmarking boosting algorithm and three advanced boosting-based algorithms for imbalanced data set. Results indicate that our approach does not sacrifice one class in favor of the other, but produces high predictions against both minority and majority classes.},
	number = {1},
	urldate = {2024-07-25},
	journal = {SIGKDD Explor. Newsl.},
	author = {Guo, Hongyu and Viktor, Herna L.},
	month = jun,
	year = {2004},
	pages = {30--39},
}


@misc{sundar2023,
	title = {Prune then distill: {Dataset} distillation with importance sampling},
	shorttitle = {Prune then distill},
	url = {https://www.amazon.science/publications/prune-then-distill-dataset-distillation-with-importance-sampling},
	abstract = {The development of large datasets for various tasks has driven the success of deep learning models but at the cost of increased label noise, duplication, collection challenges, storage capabilities, and training requirements. In this work, we investigate whether all samples in large datasets…},
	language = {en},
	urldate = {2024-07-26},
	journal = {Amazon Science},
	author = {Sundar, Anirudh and Keskin, Gokce and Chandak, Chander and Chen, I.-Fan and Ghahremani, Pegah and Ghosh, Shalini},
	year = {2023},
}

@inproceedings{holte1989,
	title = {Concept {Learning} and the {Problem} of {Small} {Disjuncts}},
	url = {https://www.semanticscholar.org/paper/Concept-Learning-and-the-Problem-of-Small-Disjuncts-Holte-Acker/e41d77b221a4a7c3eb1ffd1ceaf6dd1259afca71},
	abstract = {Ideally, definitions induced from examples should consist of all, and only, disjuncts that are meaningful (e.g., as measured by a statistical significance test) and have a low error rate. Existing inductive systems create definitions that are ideal with regard to large disjuncts, but far from ideal with regard to small disjuncts, where a small (large) disjunct is one that correctly classifies few (many) training examples. The problem with small disjuncts is that many of them have high rates of misclassification, and it is difficult to eliminate the errorprone small disjuncts from a definition without adversely affecting other disjuncts in the definition. Various approaches to this problem are evaluated, including the novel approach of using a bias different than the "maximum generality" bias. This approach, and some others, prove partly successful, but the problem of small disjuncts remains open.},
	urldate = {2024-07-26},
         booktitle={International Joint Conference on Artificial Intelligence},
 	author = {Holte, R. and Acker, L. and Porter, B.},
	month = aug,
	year = {1989},
}

@inproceedings{japkowicz2001,
	address = {Berlin, Heidelberg},
	title = {Concept-{Learning} in the {Presence} of {Between}-{Class} and {Within}-{Class} {Imbalances}},
	volume = {2056},
	isbn = {978-3-540-42144-3 978-3-540-45153-2},
	url = {http://link.springer.com/10.1007/3-540-45153-6_7},
	doi = {10.1007/3-540-45153-6_7},
	abstract = {In a concept learning problem, imbalances in the distribution of the data can occur either between the two classes or within a single class. Yet, although both types of imbalances are known to affect negatively the performance of standard classifiers, methods for dealing with the class imbalance problem usually focus on rectifying the between-class imbalance problem, neglecting to address the imbalance occuring within each class. The purpose of this paper is to extend the simplest proposed approach for dealing with the between-class imbalance problem--random re-sampling--in order to deal simultaneously with the two problems. Although re-sampling is not necessarily the best way to deal with problems of imbalance, the results reported in this paper suggest that addressing both problems simultaneously is beneficial and should be done by more sophisticated techniques as well.},
	language = {en},
	urldate = {2024-07-26},
	publisher = {Springer Berlin Heidelberg},
	author = {Japkowicz, Nathalie},
	editor = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Stroulia, Eleni and Matwin, Stan},
	year = {2001},
	doi = {10.1007/3-540-45153-6_7},
	booktitle = {Advances in Artificial Intelligence},
        note = {Series Title: Lecture Notes in Computer Science},
	pages = {67--77},
}


@article{chinn2023a,
	title = {{ENRICHing} medical imaging training sets enables more efficient machine learning},
	volume = {30},
	issn = {1527-974X},
	doi = {10.1093/jamia/ocad055},
	abstract = {OBJECTIVE: Deep learning (DL) has been applied in proofs of concept across biomedical imaging, including across modalities and medical specialties. Labeled data are critical to training and testing DL models, but human expert labelers are limited. In addition, DL traditionally requires copious training data, which is computationally expensive to process and iterate over. Consequently, it is useful to prioritize using those images that are most likely to improve a model's performance, a practice known as instance selection. The challenge is determining how best to prioritize. It is natural to prefer straightforward, robust, quantitative metrics as the basis for prioritization for instance selection. However, in current practice, such metrics are not tailored to, and almost never used for, image datasets.
MATERIALS AND METHODS: To address this problem, we introduce ENRICH-Eliminate Noise and Redundancy for Imaging Challenges-a customizable method that prioritizes images based on how much diversity each image adds to the training set.
RESULTS: First, we show that medical datasets are special in that in general each image adds less diversity than in nonmedical datasets. Next, we demonstrate that ENRICH achieves nearly maximal performance on classification and segmentation tasks on several medical image datasets using only a fraction of the available images and without up-front data labeling. ENRICH outperforms random image selection, the negative control. Finally, we show that ENRICH can also be used to identify errors and outliers in imaging datasets.
CONCLUSIONS: ENRICH is a simple, computationally efficient method for prioritizing images for expert labeling and use in DL.},
	language = {eng},
	number = {6},
	journal = {Journal of the American Medical Informatics Association: JAMIA},
	author = {Chinn, Erin and Arora, Rohit and Arnaout, Ramy and Arnaout, Rima},
	month = may,
	year = {2023},
	pmid = {37036945},
	pmcid = {PMC10198519},
	keywords = {data efficiency, data quality, deep learning, Diagnostic Imaging, Humans, Image Processing, Computer-Assisted, information theory, instance selection, Machine Learning, medical imaging, Palliative Care, Radiography},
	pages = {1079--1090},
}


@article{athalye2023a,
	title = {Domain-guided data augmentation for deep learning on medical imaging},
	volume = {18},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0282532},
	abstract = {While domain-specific data augmentation can be useful in training neural networks for medical imaging tasks, such techniques have not been widely used to date. Our objective was to test whether domain-specific data augmentation is useful for medical imaging using a well-benchmarked task: view classification on fetal ultrasound FETAL-125 and OB-125 datasets. We found that using a context-preserving cut-paste strategy, we could create valid training data as measured by performance of the resulting trained model on the benchmark test dataset. When used in an online fashion, models trained on this hybrid data performed similarly to those trained using traditional data augmentation (FETAL-125 F-score 85.33 ± 0.24 vs 86.89 ± 0.60, p-value 0.014; OB-125 F-score 74.60 ± 0.11 vs 72.43 ± 0.62, p-value 0.004). Furthermore, the ability to perform augmentations during training time, as well as the ability to apply chosen augmentations equally across data classes, are important considerations in designing a bespoke data augmentation. Finally, we provide open-source code to facilitate running bespoke data augmentations in an online fashion. Taken together, this work expands the ability to design and apply domain-guided data augmentations for medical imaging tasks.},
	language = {eng},
	number = {3},
	journal = {PloS One},
	author = {Athalye, Chinmayee and Arnaout, Rima},
	year = {2023},
	pmid = {36952442},
	pmcid = {PMC10035842},
	keywords = {Deep Learning, Female, Humans, Neural Networks, Computer, Pregnancy, Radiography, Ultrasonography, Prenatal},
	pages = {e0282532},
}


@article{spector2023,
	title = {Principles for {Health} {Information} {Collection}, {Sharing}, and {Use}: {A} {Policy} {Statement} {From} the {American} {Heart} {Association}},
	volume = {148},
	issn = {1524-4539},
	shorttitle = {Principles for {Health} {Information} {Collection}, {Sharing}, and {Use}},
	doi = {10.1161/CIR.0000000000001173},
	abstract = {The evolution of the electronic health record, combined with advances in data curation and analytic technologies, increasingly enables data sharing and harmonization. Advances in the analysis of health-related and health-proxy information have already accelerated research discoveries and improved patient care. This American Heart Association policy statement discusses how broad data sharing can be an enabling driver of progress by providing data to develop, test, and benchmark innovative methods, scalable insights, and potential new paradigms for data storage and workflow. Along with these advances come concerns about the sensitive nature of some health data, equity considerations about the involvement of historically excluded communities, and the complex intersection of laws attempting to govern behavior. Data-sharing principles are therefore necessary across a wide swath of entities, including parties who collect health information, funders, researchers, patients, legislatures, commercial companies, and regulatory departments and agencies. This policy statement outlines some of the key equity and legal background relevant to health data sharing and responsible management. It then articulates principles that will guide the American Heart Association's engagement in public policy related to data collection, sharing, and use to continue to inform its work across the research enterprise, as well as specific examples of how these principles might be applied in the policy landscape. The goal of these principles is to improve policy to support the use or reuse of health information in ways that are respectful of patients and research participants, equitable in impact in terms of both risks and potential benefits, and beneficial across broad and demographically diverse communities in the United States.},
	language = {eng},
	number = {13},
	journal = {Circulation},
	author = {Spector-Bagdady, Kayte and Armoundas, Antonis A. and Arnaout, Rima and Hall, Jennifer L. and Yeager McSwain, Brooke and Knowles, Joshua W. and Price, W. Nicholson and Rawat, Danda B. and Riegel, Barbara and Wang, Tracy Y. and Wiley, Kevin and Chung, Mina K. and {American Heart Association Advocacy Coordinating Committee}},
	month = sep,
	year = {2023},
	pmid = {37646159},
	pmcid = {PMC10912036},
	keywords = {AHA Scientific Statements, American Heart Association, consumer health information, Data Collection, ethics, research, Humans, Information Dissemination, policy, social justice, technology, United States},
	pages = {1061--1069},
}

@article{sachdeva2024,
	title = {Novel {Techniques} in {Imaging} {Congenital} {Heart} {Disease}: {JACC} {Scientific} {Statement}},
	volume = {83},
	issn = {1558-3597},
	shorttitle = {Novel {Techniques} in {Imaging} {Congenital} {Heart} {Disease}},
	doi = {10.1016/j.jacc.2023.10.025},
	abstract = {Recent years have witnessed exponential growth in cardiac imaging technologies, allowing better visualization of complex cardiac anatomy and improved assessment of physiology. These advances have become increasingly important as more complex surgical and catheter-based procedures are evolving to address the needs of a growing congenital heart disease population. This state-of-the-art review presents advances in echocardiography, cardiac magnetic resonance, cardiac computed tomography, invasive angiography, 3-dimensional modeling, and digital twin technology. The paper also highlights the integration of artificial intelligence with imaging technology. While some techniques are in their infancy and need further refinement, others have found their way into clinical workflow at well-resourced centers. Studies to evaluate the clinical value and cost-effectiveness of these techniques are needed. For techniques that enhance the value of care for congenital heart disease patients, resources will need to be allocated for education and training to promote widespread implementation.},
	language = {eng},
	number = {1},
	journal = {Journal of the American College of Cardiology},
	author = {Sachdeva, Ritu and Armstrong, Aimee K. and Arnaout, Rima and Grosse-Wortmann, Lars and Han, B. Kelly and Mertens, Luc and Moore, Ryan A. and Olivieri, Laura J. and Parthiban, Anitha and Powell, Andrew J.},
	month = jan,
	year = {2024},
	pmid = {38171712},
	pmcid = {PMC10947556},
	keywords = {angiography, artificial intelligence, Artificial Intelligence, cardiac computed tomography, Cardiac Imaging Techniques, cardiac magnetic resonance, digital twin technology, echocardiography, Echocardiography, Heart Defects, Congenital, Humans, Magnetic Resonance Imaging},
	pages = {63--81},
}

@article{dey2023b,
	title = {Proceedings of the {NHLBI} {Workshop} on {Artificial} {Intelligence} in {Cardiovascular} {Imaging}: {Translation} to {Patient} {Care}},
	volume = {16},
	issn = {1876-7591},
	shorttitle = {Proceedings of the {NHLBI} {Workshop} on {Artificial} {Intelligence} in {Cardiovascular} {Imaging}},
	doi = {10.1016/j.jcmg.2023.05.012},
	abstract = {Artificial intelligence (AI) promises to revolutionize many fields, but its clinical implementation in cardiovascular imaging is still rare despite increasing research. We sought to facilitate discussion across several fields and across the lifecycle of research, development, validation, and implementation to identify challenges and opportunities to further translation of AI in cardiovascular imaging. Furthermore, it seemed apparent that a multidisciplinary effort across institutions would be essential to overcome these challenges. This paper summarizes the proceedings of the National Heart, Lung, and Blood Institute-led workshop, creating consensus around needs and opportunities for institutions at several levels to support and advance research in this field and support future translation.},
	language = {eng},
	number = {9},
	journal = {JACC. Cardiovascular imaging},
	author = {Dey, Damini and Arnaout, Rima and Antani, Sameer and Badano, Aldo and Jacques, Louis and Li, Huiqing and Leiner, Tim and Margerrison, Edward and Samala, Ravi and Sengupta, Partho P. and Shah, Sanjiv J. and Slomka, Piotr and Williams, Michelle C. and Bandettini, W. Patricia and Sachdev, Vandana},
	month = sep,
	year = {2023},
	pmid = {37480904},
	pmcid = {PMC10524663},
	keywords = {AI algorithms, artificial intelligence, Artificial Intelligence, cardiovascular imaging, Cardiovascular System, data science, deep learning, Humans, machine learning, National Heart, Lung, and Blood Institute (U.S.), Patient Care, Predictive Value of Tests, United States},
	pages = {1209--1223},
}

@article{chowdhury2020,
	title = {Can {AI} help in screening {Viral} and {COVID}-19 pneumonia?},
	volume = {8},
	issn = {2169-3536},
	url = {http://arxiv.org/abs/2003.13145},
	doi = {10.1109/ACCESS.2020.3010287},
	abstract = {Coronavirus disease (COVID-19) is a pandemic disease, which has already caused thousands of causalities and infected several millions of people worldwide. Any technological tool enabling rapid screening of the COVID-19 infection with high accuracy can be crucially helpful to healthcare professionals. The main clinical tool currently in use for the diagnosis of COVID-19 is the Reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less-sensitive and requires specialized medical personnel. X-ray imaging is an easily accessible tool that can be an excellent alternative in the COVID-19 diagnosis. This research was taken to investigate the utility of artificial intelligence (AI) in the rapid and accurate detection of COVID-19 from chest X-ray images. The aim of this paper is to propose a robust technique for automatic detection of COVID-19 pneumonia from digital chest X-ray images applying pre-trained deep-learning algorithms while maximizing the detection accuracy. A public database was created by the authors combining several public databases and also by collecting images from recently published articles. The database contains a mixture of 423 COVID-19, 1485 viral pneumonia, and 1579 normal chest X-ray images. Transfer learning technique was used with the help of image augmentation to train and validate several pre-trained deep Convolutional Neural Networks (CNNs). The networks were trained to classify two different schemes: i) normal and COVID-19 pneumonia; ii) normal, viral and COVID-19 pneumonia with and without image augmentation. The classification accuracy, precision, sensitivity, and specificity for both the schemes were 99.7\%, 99.7\%, 99.7\% and 99.55\% and 97.9\%, 97.95\%, 97.9\%, and 98.8\%, respectively.},
	urldate = {2024-06-12},
	journal = {IEEE Access},
	author = {Chowdhury, Muhammad E. H. and Rahman, Tawsifur and Khandakar, Amith and Mazhar, Rashid and Kadir, Muhammad Abdul and Mahbub, Zaid Bin and Islam, Khandaker Reajul and Khan, Muhammad Salman and Iqbal, Atif and Al-Emadi, Nasser and Reaz, Mamun Bin Ibne and Islam, T. I.},
	year = {2020},
	note = {arXiv:2003.13145 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {132665--132676},
}

@article{rahman2021,
	title = {Exploring the effect of image enhancement techniques on {COVID}-19 detection using chest {X}-ray images},
	volume = {132},
	issn = {0010-4825},
	url = {sciencedirect.com/science/article/pii/S001048252100113X},
	doi = {10.1016/j.compbiomed.2021.104319},
	abstract = {Computer-aided diagnosis for the reliable and fast detection of coronavirus disease (COVID-19) has become a necessity to prevent the spread of the virus during the pandemic to ease the burden on the healthcare system. Chest X-ray (CXR) imaging has several advantages over other imaging and detection techniques. Numerous works have been reported on COVID-19 detection from a smaller set of original X-ray images. However, the effect of image enhancement and lung segmentation of a large dataset in COVID-19 detection was not reported in the literature. We have compiled a large X-ray dataset (COVQU) consisting of 18,479 CXR images with 8851 normal, 6012 non-COVID lung infections, and 3616 COVID-19 CXR images and their corresponding ground truth lung masks. To the best of our knowledge, this is the largest public COVID positive database and the lung masks. Five different image enhancement techniques: histogram equalization (HE), contrast limited adaptive histogram equalization (CLAHE), image complement, gamma correction, and balance contrast enhancement technique (BCET) were used to investigate the effect of image enhancement techniques on COVID-19 detection. A novel U-Net model was proposed and compared with the standard U-Net model for lung segmentation. Six different pre-trained Convolutional Neural Networks (CNNs) (ResNet18, ResNet50, ResNet101, InceptionV3, DenseNet201, and ChexNet) and a shallow CNN model were investigated on the plain and segmented lung CXR images. The novel U-Net model showed an accuracy, Intersection over Union (IoU), and Dice coefficient of 98.63\%, 94.3\%, and 96.94\%, respectively for lung segmentation. The gamma correction-based enhancement technique outperforms other techniques in detecting COVID-19 from the plain and the segmented lung CXR images. Classification performance from plain CXR images is slightly better than the segmented lung CXR images; however, the reliability of network performance is significantly improved for the segmented lung images, which was observed using the visualization technique. The accuracy, precision, sensitivity, F1-score, and specificity were 95.11\%, 94.55\%, 94.56\%, 94.53\%, and 95.59\% respectively for the segmented lung images. The proposed approach with very reliable and comparable performance will boost the fast and robust COVID-19 detection using chest X-ray images.},
	urldate = {2024-06-12},
	journal = {Computers in Biology and Medicine},
	author = {Rahman, Tawsifur and Khandakar, Amith and Qiblawey, Yazan and Tahir, Anas and Kiranyaz, Serkan and Abul Kashem, Saad Bin and Islam, Mohammad Tariqul and Al Maadeed, Somaya and Zughaier, Susu M. and Khan, Muhammad Salman and Chowdhury, Muhammad E. H.},
	month = may,
	year = {2021},
	keywords = {Chest X-ray images, Convolutional neural networks, COVID-19, Image enhancement, Lung segmentation},
	pages = {104319},
}


@article{arnaoutEnsemble2021,
	title = {An ensemble of neural networks provides expert-level prenatal detection of complex congenital heart disease},
	volume = {27},
	issn = {1546-170X},
	doi = {10.1038/s41591-021-01342-5},
	abstract = {Congenital heart disease (CHD) is the most common birth defect. Fetal screening ultrasound provides five views of the heart that together can detect 90\% of complex CHD, but in practice, sensitivity is as low as 30\%. Here, using 107,823 images from 1,326 retrospective echocardiograms and screening ultrasounds from 18- to 24-week fetuses, we trained an ensemble of neural networks to identify recommended cardiac views and distinguish between normal hearts and complex CHD. We also used segmentation models to calculate standard fetal cardiothoracic measurements. In an internal test set of 4,108 fetal surveys (0.9\% CHD, {\textgreater}4.4 million images), the model achieved an area under the curve (AUC) of 0.99, 95\% sensitivity (95\% confidence interval (CI), 84-99\%), 96\% specificity (95\% CI, 95-97\%) and 100\% negative predictive value in distinguishing normal from abnormal hearts. Model sensitivity was comparable to that of clinicians and remained robust on outside-hospital and lower-quality images. The model's decisions were based on clinically relevant features. Cardiac measurements correlated with reported measures for normal and abnormal hearts. Applied to guideline-recommended imaging, ensemble learning models could significantly improve detection of fetal CHD, a critical and global diagnostic challenge.},
	language = {eng},
	number = {5},
	journal = {Nature Medicine},
	author = {Arnaout, Rima and Curran, Lara and Zhao, Yili and Levine, Jami C. and Chinn, Erin and Moon-Grady, Anita J.},
	month = may,
	year = {2021},
	pmid = {33990806},
	note = {Number: 5},
	keywords = {Humans, Biometry, Female, Adult, Myocardium, Sensitivity and Specificity, Mass Screening, Young Adult, Pregnancy, Prenatal Diagnosis, Fetus, Heart Defects, Congenital, Neural Networks, Computer, Ultrasonography, Prenatal, Heart, Pregnancy Trimester, Second, Echocardiography, Three-Dimensional, Thorax},
	pages = {882--891},
}

@article{lits2023,
	title = {The {Liver} {Tumor} {Segmentation} {Benchmark} ({LiTS})},
	volume = {84},
	issn = {13618415},
	url = {http://arxiv.org/abs/1901.04056},
	doi = {10.1016/j.media.2022.102680},
	abstract = {In this work, we report the set-up and results of the Liver Tumor Segmentation Benchmark (LiTS), which was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 and the International Conferences on Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2017 and 2018. The image dataset is diverse and contains primary and secondary tumors with varied sizes and appearances with various lesion-to-background levels (hyper-/hypo-dense), created in collaboration with seven hospitals and research institutions. Seventy-five submitted liver and liver tumor segmentation algorithms were trained on a set of 131 computed tomography (CT) volumes and were tested on 70 unseen test images acquired from different patients. We found that not a single algorithm performed best for both liver and liver tumors in the three events. The best liver segmentation algorithm achieved a Dice score of 0.963, whereas, for tumor segmentation, the best algorithms achieved Dices scores of 0.674 (ISBI 2017), 0.702 (MICCAI 2017), and 0.739 (MICCAI 2018). Retrospectively, we performed additional analysis on liver tumor detection and revealed that not all top-performing segmentation algorithms worked well for tumor detection. The best liver tumor detection method achieved a lesion-wise recall of 0.458 (ISBI 2017), 0.515 (MICCAI 2017), and 0.554 (MICCAI 2018), indicating the need for further research. LiTS remains an active benchmark and resource for research, e.g., contributing the liver-related segmentation tasks in {\textbackslash}url\{http://medicaldecathlon.com/\}. In addition, both data and online evaluation are accessible via {\textbackslash}url\{lits-challenge.com\}.},
	urldate = {2024-06-06},
	journal = {Medical Image Analysis},
	author = {Bilic, Patrick and Christ, Patrick and Li, Hongwei Bran and Vorontsov, Eugene and Ben-Cohen, Avi and Kaissis, Georgios and Szeskin, Adi and Jacobs, Colin and Mamani, Gabriel Efrain Humpire and Chartrand, Gabriel and Lohöfer, Fabian and Holch, Julian Walter and Sommer, Wieland and Hofmann, Felix and Hostettler, Alexandre and Lev-Cohain, Naama and Drozdzal, Michal and Amitai, Michal Marianne and Vivantik, Refael and Sosna, Jacob and Ezhov, Ivan and Sekuboyina, Anjany and Navarro, Fernando and Kofler, Florian and Paetzold, Johannes C. and Shit, Suprosanna and Hu, Xiaobin and Lipková, Jana and Rempfler, Markus and Piraud, Marie and Kirschke, Jan and Wiestler, Benedikt and Zhang, Zhiheng and Hülsemeyer, Christian and Beetz, Marcel and Ettlinger, Florian and Antonelli, Michela and Bae, Woong and Bellver, Míriam and Bi, Lei and Chen, Hao and Chlebus, Grzegorz and Dam, Erik B. and Dou, Qi and Fu, Chi-Wing and Georgescu, Bogdan and Giró-i-Nieto, Xavier and Gruen, Felix and Han, Xu and Heng, Pheng-Ann and Hesser, Jürgen and Moltz, Jan Hendrik and Igel, Christian and Isensee, Fabian and Jäger, Paul and Jia, Fucang and Kaluva, Krishna Chaitanya and Khened, Mahendra and Kim, Ildoo and Kim, Jae-Hun and Kim, Sungwoong and Kohl, Simon and Konopczynski, Tomasz and Kori, Avinash and Krishnamurthi, Ganapathy and Li, Fan and Li, Hongchao and Li, Junbo and Li, Xiaomeng and Lowengrub, John and Ma, Jun and Maier-Hein, Klaus and Maninis, Kevis-Kokitsi and Meine, Hans and Merhof, Dorit and Pai, Akshay and Perslev, Mathias and Petersen, Jens and Pont-Tuset, Jordi and Qi, Jin and Qi, Xiaojuan and Rippel, Oliver and Roth, Karsten and Sarasua, Ignacio and Schenk, Andrea and Shen, Zengming and Torres, Jordi and Wachinger, Christian and Wang, Chunliang and Weninger, Leon and Wu, Jianrong and Xu, Daguang and Yang, Xiaoping and Yu, Simon Chun-Ho and Yuan, Yading and Yu, Miao and Zhang, Liping and Cardoso, Jorge and Bakas, Spyridon and Braren, Rickmer and Heinemann, Volker and Pal, Christopher and Tang, An and Kadoury, Samuel and Soler, Luc and van Ginneken, Bram and Greenspan, Hayit and Joskowicz, Leo and Menze, Bjoern},
	month = feb,
	year = {2023},
	note = {arXiv:1901.04056 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {102680},
}


% ENRICH paper
@article {Chinn2021,
	author = {Erin Chinn and Rohit Arora and Ramy Arnaout and Rima Arnaout},
	title = {ENRICH: Exploiting Image Similarity to Maximize Efficient Machine Learning in Medical Imaging},
	elocation-id = {2021.05.22.21257645},
	publisher = {Cold Spring Harbor Laboratory Press},
	abstract = {Deep learning (DL) has been applied with success in proofs of concept across biomedical imaging, including across modalities and medical specialties 1{\textendash}17. Labeled data is critical to training and testing DL models, and such models traditionally require large amounts of training data, straining the limited (human) resources available for expert labeling/annotation. It would be ideal to prioritize labeling those images that are most likely to improve model performance and skip images that are redundant. However, straightforward, robust, and quantitative metrics for measuring and eliminating redundancy in datasets have not yet been described. Here, we introduce a new method, ENRICH (Eliminate Needless Redundancy for Imaging Challenges), for assessing image dataset redundancy and test it on a well-benchmarked medical imaging dataset3. First, we compute pairwise similarity metrics for images in a given dataset, resulting in a matrix of pairwise-similarity values. We then rank images based on this matrix and use these rankings to curate the dataset, to minimize dataset redundancy. Using this method, we achieve similar AUC scores in a binary classification task with just a fraction of our original dataset (AUC of 0.99 {\textpm} 1.35e-05 on 44 percent of available images vs. AUC of 0.99 {\textpm} 9.32e-06 on all available images, p-value 0.0002) and better scores than same-sized training subsets chosen at random. We also demonstrate similar Jaccard sores in a multi-class segmentation task while eliminating redundant images. (average Jaccard index of 0.58 on 80 percent of available images vs 0.60 on all available images). Thus, algorithms that reduce dataset redundancy based on image similarity can significantly reduce the number of training images required, while preserving performance, in medical imaging datasets.Competing Interest StatementThe authors have declared no competing interest.Funding StatementEC, RA, RA, and RA were supported by the Department of Defense (W81XWH-19-1-0294) and the National Heart, Lung, and Blood Institute (NIH R01HL146398). RA and RA were supported by the National Institutes of Allergy and Infectious Diseases (NIH R01AI148747-01). EC and RA were supported by the American Heart Association (17IGMV33870001).Author DeclarationsI confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.YesThe details of the IRB/oversight body that provided approval or exemption for the research described are given below:All datasets were obtained retrospectively and de-identified, with waived consent in compliance with the Institutional Review Board (IRB) at the University of California, San Francisco (UCSF). IRB 17-21481All necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived.YesI understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).YesI have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.YesDue to the sensitive nature of patient data, we are not able to make these data publicly available at this time.},
	URL = {medrxiv.org/content/early/2021/05/25/2021.05.22.21257645},
	eprint = {medrxiv.org/content/10.1101/2021.05.22.21257645},
        archivePrefix={medrxiv},
        journal = {Journal of the American Medical Informatics Association},
        volume = {30},
        number = {6},
        pages = {1079-1090},
        year = {2023},
        month = {04},
        issn = {1527-974X},
        doi = {10.1093/jamia/ocad055},
}


@article{madani2018,
	title = {Fast and accurate view classification of echocardiograms using deep learning},
	volume = {1},
	issn = {2398-6352},
	url = {nature.com/articles/s41746-017-0013-1},
	doi = {10.1038/s41746-017-0013-1},
	abstract = {Abstract 
            Echocardiography is essential to cardiology. However, the need for human interpretation has limited echocardiography’s full potential for precision medicine. Deep learning is an emerging tool for analyzing images but has not yet been widely applied to echocardiograms, partly due to their complex multi-view format. The essential first step toward comprehensive computer-assisted echocardiographic interpretation is determining whether computers can learn to recognize these views. We trained a convolutional neural network to simultaneously classify 15 standard views (12 video, 3 still), based on labeled still images and videos from 267 transthoracic echocardiograms that captured a range of real-world clinical variation. Our model classified among 12 video views with 97.8\% overall test accuracy without overfitting. Even on single low-resolution images, accuracy among 15 views was 91.7\% vs. 70.2–84.0\% for board-certified echocardiographers. Data visualization experiments showed that the model recognizes similarities among related views and classifies using clinically relevant image features. Our results provide a foundation for artificial intelligence-assisted echocardiographic interpretation.},
	pages = {6},
	number = {1},
	journal = {npj Digital Medicine},
	shortjournal = {npj Digital Med},
	author = {Madani, Ali and Arnaout, Ramy and Mofrad, Mohammad and Arnaout, Rima},
	urldate = {2024-03-25},
	date = {2018-03-21},
        year = {2018},
	langid = {english},
}


@article{Bayes:1764vd,
    author = "Bayes, Rev., Thomas",
    title = "{An essay toward solving a problem in the doctrine of chances}",
    doi = "10.1098/rstl.1763.0053",
    journal = "Phil. Trans. Roy. Soc. Lond.",
    volume = "53",
    pages = "370--418",
    year = "1764"
}

@article{Shannon:1948zz,
    author = "Shannon, Claude Elwood",
    title = "{A mathematical theory of communication}",
    journal = "Bell Syst. Tech. J.",
    volume = "27",
    pages = "379--423",
    year = "1948"
}

@article{simpson1949,
	title = {Measurement of Diversity},
	volume = {163},
	issn = {0028-0836, 1476-4687},
	url = {nature.com/articles/163688a0},
	doi = {10.1038/163688a0},
	pages = {688--688},
	number = {4148},
	journal = {Nature},
	shortjournal = {Nature},
	author = {Simpson, E. H.},
	urldate = {2023-07-07},
	date = {1949-04},
        year = {1949},
        month = {Apr},
	langid = {english},
}

@article{renyi1961,
    author="RENYI, A.",
    title="On measures of entropy and information",
    journal="Proceedings of the fourth berkeley symposium on mathematical statistics and probability, 1961",
    publisher="University of California Press",
    year="1961",
    URL="cir.nii.ac.jp/crid/1572261550246171008"
}

@article{berger1970,
	title = {Diversity of planktonic foraminifera in deep-sea sediments},
	volume = {168},
	issn = {0036-8075},
	doi = {10.1126/science.168.3937.1345},
	pages = {1345--1347},
	number = {3937},
	journal = {Science (New York, N.Y.)},
	shortjournal = {Science},
	author = {Berger, W. H. and Parker, F. L.},
	date = {1970-06-12},
        year = {1970},
	pmid = {17731043},
}

@article{hill1973,
	title = {Diversity and Evenness: A Unifying Notation and Its Consequences},
	volume = {54},
	issn = {0012-9658, 1939-9170},
	url = {esajournals.onlinelibrary.wiley.com/doi/10.2307/1934352},
	doi = {10.2307/1934352},
	shorttitle = {Diversity and Evenness},
	abstract = {Three commonly used measures of diversity, Simpson's index, Shannon's entropy, and the total number of species, are related to Renyi's definition of a generalized entropy. A unified concept of diversity is presented, according to which there is a continuum of possible diversity measures. In a sense which becomes apparent, these measures provide estimates of the effective number of species present, and differ only in their tendency to include or to ignore the relatively rarer species. The notion of the diversity of a community as opposed to that of a sample is examined, and is related to the asymptotic form of the species—abundance curve. A new and plausible definition of evenness is derived.},
	pages = {427--432},
	number = {2},
	journal = {Ecology},
	shortjournal = {Ecology},
	author = {Hill, M. O.},
	urldate = {2024-03-19},
	date = {1973-03},
        year = {1973},
	langid = {english},
}

@article{jost2007,
	title = {Partitioning diversity into independent alpha and beta components},
	volume = {88},
	issn = {0012-9658},
	doi = {10.1890/06-1736.1},
	abstract = {Existing general definitions of beta diversity often produce a beta with a hidden dependence on alpha. Such a beta cannot be used to compare regions that differ in alpha diversity. To avoid misinterpretation, existing definitions of alpha and beta must be replaced by a definition that partitions diversity into independent alpha and beta components. Such a unique definition is derived here. When these new alpha and beta components are transformed into their numbers equivalents (effective numbers of elements), Whittaker's multiplicative law (alpha x beta = gamma) is necessarily true for all indices. The new beta gives the effective number of distinct communities. The most popular similarity and overlap measures of ecology (Jaccard, Sorensen, Horn, and Morisita-Horn indices) are monotonic transformations of the new beta diversity. Shannon measures follow deductively from this formalism and do not need to be borrowed from information theory; they are shown to be the only standard diversity measures which can be decomposed into meaningful independent alpha and beta components when community weights are unequal.},
	pages = {2427--2439},
	number = {10},
	journal = {Ecology},
	shortjournal = {Ecology},
	author = {Jost, Lou},
	date = {2007-10},
        year = {2007},
	pmid = {18027744},
	keywords = {Animals, Biodiversity, Ecosystem, Environment, Models, Statistical, Population Density, Population Dynamics},
}

@article{chao2010,
	title = {Phylogenetic diversity measures based on Hill numbers},
	volume = {365},
	issn = {0962-8436},
	url = {ncbi.nlm.nih.gov/pmc/articles/PMC2982003/},
	doi = {10.1098/rstb.2010.0272},
	abstract = {We propose a parametric class of phylogenetic diversity ({PD}) measures that are sensitive to both species abundance and species taxonomic or phylogenetic distances. This work extends the conventional parametric species-neutral approach (based on ‘effective number of species’ or Hill numbers) to take into account species relatedness, and also generalizes the traditional phylogenetic approach (based on ‘total phylogenetic length’) to incorporate species abundances. The proposed measure quantifies ‘the mean effective number of species’ over any time interval of interest, or the ‘effective number of maximally distinct lineages’ over that time interval. The product of the measure and the interval length quantifies the ‘branch diversity’ of the phylogenetic tree during that interval. The new measures generalize and unify many existing measures and lead to a natural definition of taxonomic diversity as a special case. The replication principle (or doubling property), an important requirement for species-neutral diversity, is generalized to {PD}. The widely used Rao's quadratic entropy and the phylogenetic entropy do not satisfy this essential property, but a simple transformation converts each to our measures, which do satisfy the property. The proposed approach is applied to forest data for interpreting the effects of thinning.},
	pages = {3599--3609},
	number = {1558},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	shortjournal = {Philos Trans R Soc Lond B Biol Sci},
	author = {Chao, Anne and Chiu, Chun-Huo and Jost, Lou},
	urldate = {2022-09-16},
	date = {2010-11-27},
        year = {2010},
	pmid = {20980309},
	pmcid = {PMC2982003},
}

@article{leinster2012,
	title = {Measuring diversity: the importance of species similarity},
	volume = {93},
	issn = {0012-9658},
	doi = {10.1890/10-2402.1},
	shorttitle = {Measuring diversity},
	abstract = {Realistic measures of biodiversity should reflect not only the relative abundances of species, but also the differences between them. We present a natural family of diversity measures taking both factors into account. This is not just another addition to the already long list of diversity indices. Instead, a single formula subsumes many of the most popular indices, including Shannon's, Simpson's, species richness, and Rao's quadratic entropy. These popular indices can then be used and understood in a unified way, and the relationships between them are made plain. The new measures are, moreover, effective numbers, so that percentage changes and ratio comparisons of diversity value are meaningful. We advocate the use of diversity profiles, which provide a faithful graphical representation of the shape of a community; they show how the perceived diversity changes as the emphasis shifts from rare to common species. Communities can usefully be compared by comparing their diversity profiles. We show by example that this is a far more subtle method than any relying on a single statistic. Some ecologists view diversity indices with suspicion, questioning whether they are biologically meaningful. By dropping the naive assumption that distinct species have nothing in common, working with effective numbers, and using diversity profiles, we arrive at a system of diversity measurement that should lay much of this suspicion to rest.},
	pages = {477--489},
	number = {3},
	journal = {Ecology},
	shortjournal = {Ecology},
	author = {Leinster, Tom and Cobbold, Christina A.},
	date = {2012-03},
        year = {2012},
	pmid = {22624203},
	keywords = {Adaptation, Biological, Animals, Anthozoa, Biodiversity, Butterflies, Species Specificity},
}

@misc{reeve2016,
      title={How to partition diversity}, 
      author={Richard Reeve and Tom Leinster and Christina A. Cobbold and Jill Thompson and Neil Brummitt and Sonia N. Mitchell and Louise Matthews},
      year={2016},
      eprint={1404.6520},
      archivePrefix={arXiv},
      primaryClass={q-bio.QM}
}

@misc{leinster2021,
      title={Entropy and Diversity: The Axiomatic Approach}, 
      author={Tom Leinster},
      year={2022},
      eprint={2012.02113},
      archivePrefix={arXiv},
      primaryClass={q-bio.PE},
	shorttitle = {Entropy and {Diversity}},
	url = {http://arxiv.org/abs/2012.02113},
	abstract = {This book brings new mathematical rigour to the ongoing vigorous debate on how to quantify biological diversity. The question "what is diversity?" has surprising mathematical depth, and breadth too: this book involves parts of mathematics ranging from information theory, functional equations and probability theory to category theory, geometric measure theory and number theory. It applies the power of the axiomatic method to a biological problem of pressing concern, but the new concepts and theorems are also motivated from a purely mathematical perspective. The main narrative thread requires no more than an undergraduate course in analysis. No familiarity with entropy or diversity is assumed.},
	urldate = {2022-09-16},
	note = {arXiv:2012.02113 [cs, math, q-bio]},
	keywords = {92B99, 94A17, 39B99, 26E60, 18D50, Computer Science - Information Theory, Mathematics - Category Theory, Mathematics - Classical Analysis and ODEs, Quantitative Biology - Populations and Evolution, Quantitative Biology - Quantitative Methods},
}

@article{Srivastava:2014,
    title={Dropout: a simple way to prevent neural networks from overfitting},
    author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
    journal={The journal of machine learning research},
    volume={15},
    number={1},
    pages={1929--1958},
    year={2014},
    publisher={JMLR. org}
}


@InProceedings{Gal:2015,
    title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
    author = 	 {Gal, Yarin and Ghahramani, Zoubin},
    eprint = "1506.02142",
    archivePrefix = "arXiv",
    primaryClass = "stat.ML",
    booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
    pages = 	 {1050--1059},
    year = 	 {2016},
    editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
    volume = 	 {48},
    series = 	 {Proceedings of Machine Learning Research},
    address = 	 {New York, New York, USA},
    month = 	 {20--22 Jun},
    publisher =    {PMLR},
    pdf = 	 {proceedings.mlr.press/v48/gal16.pdf},
    url = 	 {proceedings.mlr.press/v48/gal16.html},
    abstract = 	 {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.},
    keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}

@InProceedings{Gal:2017,
    title = 	 {Deep {B}ayesian Active Learning with Image Data},
    author =       {Yarin Gal and Riashat Islam and Zoubin Ghahramani},
    eprint = "1703.02910",
    archivePrefix = "arXiv",
    primaryClass = "cs.LG",
    booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
    pages = 	 {1183--1192},
    year = 	 {2017},
    editor = 	 {Precup, Doina and Teh, Yee Whye},
    volume = 	 {70},
    series = 	 {Proceedings of Machine Learning Research},
    month = 	 {06--11 Aug},
    publisher =    {PMLR},
    pdf = 	 {http://proceedings.mlr.press/v70/gal17a/gal17a.pdf},
    url = 	 {proceedings.mlr.press/v70/gal17a.html},
    abstract = 	 {Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolutional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).},
    keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}
}

@InProceedings{Mehta:2022,
    author="Mehta, Raghav
        and Shui, Changjian
        and Nichyporuk, Brennan
        and Arbel, Tal",
    editor="Sudre, Carole H.
        and Baumgartner, Christian F.
        and Dalca, Adrian
        and Qin, Chen
        and Tanno, Ryutaro
        and Van Leemput, Koen
        and Wells III, William M.",
    title="Information Gain Sampling for Active Learning in Medical Image Classification",
    booktitle="Uncertainty for Safe Utilization of Machine Learning in Medical Imaging",
    year="2022",
    publisher="Springer Nature Switzerland",
    address="Cham",
    pages="135--145",
    eprint = "2208.00974",
    archivePrefix = "arXiv",
    primaryClass = "cs.CV",
    doi = {10.1007/978-3-031-16749-2_13},
    abstract="Large, annotated datasets are not widely available in medical image analysis due to the prohibitive time, costs, and challenges associated with labelling large datasets. Unlabelled datasets are easier to obtain, and in many contexts, it would be feasible for an expert to provide labels for a small subset of images. This work presents an information-theoretic active learning framework that guides the optimal selection of images from the unlabelled pool to be labeled based on maximizing the expected information gain (EIG) on an evaluation dataset. Experiments are performed on two different medical image classification datasets: multi-class diabetic retinopathy disease scale classification and multi-class skin lesion classification. Results indicate that by adapting EIG to account for class-imbalances, our proposed Adapted Expected Information Gain (AEIG) outperforms several popular baselines including the diversity based CoreSet and uncertainty based maximum entropy sampling. Specifically, AEIG achieves {\$}{\$}{\{}{\backslash}sim {\}}95{\backslash}{\%}{\$}{\$}∼95{\%}of overall performance with only 19{\%} of the training data, while other active learning approaches require around 25{\%}. We show that, by careful design choices, our model can be integrated into existing deep learning classifiers.",
    isbn="978-3-031-16749-2",
    keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

% Datasets and software packages

@misc{mnist,
  title={MNIST handwritten digit database, 1998},
  author={LeCun, Yann and Cortes, Corinna and Burges, Chris and others},
  url={http://yann. lecun. com/exdb/mnist},
  year={1998}
}

@misc{greylock,
      title={$\textit{greylock}$: A Python Package for Measuring The Composition of Complex Datasets}, 
      author={Phuc Nguyen and Rohit Arora and Elliot D. Hill and Jasper Braun and Alexandra Morgan and Liza M. Quintana and Gabrielle Mazzoni and Ghee Rye Lee and Rima Arnaout and Ramy Arnaout},
      year={2023},
      eprint={2401.00102},
      archivePrefix={arXiv},
      primaryClass={q-bio.QM}
}

@article{medmnistv2,
    title={MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification},
    author={Yang, Jiancheng and Shi, Rui and Wei, Donglai and Liu, Zequan and Zhao, Lin and Ke, Bilian and Pfister, Hanspeter and Ni, Bingbing},
    journal={Scientific Data},
    volume={10},
    number={1},
    pages={41},
    year={2023},
    publisher={Nature Publishing Group UK London},
	url = {http://arxiv.org/abs/2110.14795},
	doi = {10.1038/s41597-022-01721-8},
	eprinttype = {arxiv},
	eprint = {2110.14795},
    primaryClass = {cs, eess},
}

@inproceedings{medmnistv1,
    title={MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis},
    author={Yang, Jiancheng and Shi, Rui and Ni, Bingbing},
    booktitle={IEEE 18th International Symposium on Biomedical Imaging (ISBI)},
    pages={191--195},
    year={2021}
}

@misc{resnet18,
	title = {Deep Residual Learning for Image Recognition},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the {ImageNet} dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than {VGG} nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the {ImageNet} test set. This result won the 1st place on the {ILSVRC} 2015 classification task. We also present analysis on {CIFAR}-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the {COCO} object detection dataset. Deep residual nets are foundations of our submissions to {ILSVRC} \& {COCO} 2015 competitions, where we also won the 1st places on the tasks of {ImageNet} detection, {ImageNet} localization, {COCO} detection, and {COCO} segmentation.},
	number = {{arXiv}:1512.03385},
	publisher = {{arXiv}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2024-02-07},
        year = {2015},
	date = {2015-12-10},
	eprinttype = {arxiv},
	eprint = {1512.03385},
    primaryClass = {cs},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@misc{pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


%% Dump from Ramy's zotero:


@book{abhishek2023,
	title = {Machine Learning for Imbalanced Data: Tackle imbalanced datasets using machine learning and deep learning techniques},
	isbn = {978-1-80107-083-6},
	shorttitle = {Machine Learning for Imbalanced Data},
	abstract = {Take your machine learning expertise to the next level with this essential guide, utilizing libraries like imbalanced-learn, {PyTorch}, scikit-learn, pandas, and {NumPy} to maximize model performance and tackle imbalanced {dataKey} {FeaturesUnderstand} how to use modern machine learning frameworks with detailed explanations, illustrations, and code {samplesLearn} cutting-edge deep learning techniques to overcome data {imbalanceExplore} different methods for dealing with skewed data in {ML} and {DL} {applicationsPurchase} of the print or Kindle book includes a free {eBook} in the {PDF} {formatBook} {DescriptionAs} machine learning practitioners, we often encounter imbalanced datasets in which one class has considerably fewer instances than the other. Many machine learning algorithms assume an equilibrium between majority and minority classes, leading to suboptimal performance on imbalanced data. This comprehensive guide helps you address this class imbalance to significantly improve model performance.Machine Learning for Imbalanced Data begins by introducing you to the challenges posed by imbalanced datasets and the importance of addressing these issues. It then guides you through techniques that enhance the performance of classical machine learning models when using imbalanced data, including various sampling and cost-sensitive learning methods.As you progress, you'll delve into similar and more advanced techniques for deep learning models, employing {PyTorch} as the primary framework. Throughout the book, hands-on examples will provide working and reproducible code that'll demonstrate the practical implementation of each technique.By the end of this book, you'll be adept at identifying and addressing class imbalances and confidently applying various techniques, including sampling, cost-sensitive techniques, and threshold adjustment, while using traditional machine learning or deep learning models.What you will {learnUse} imbalanced data in your machine learning models {effectivelyExplore} the metrics used when classes are {imbalancedUnderstand} how and when to apply various sampling methods such as over-sampling and under-{samplingApply} data-based, algorithm-based, and hybrid approaches to deal with class {imbalanceCombine} and choose from various options for data balancing while avoiding common {pitfallsUnderstand} the concepts of model calibration and threshold adjustment in the context of dealing with imbalanced {datasetsWho} this book is {forThis} book is for machine learning practitioners who want to effectively address the challenges of imbalanced datasets in their projects. Data scientists, machine learning engineers/scientists, research scientists/engineers, and data scientists/engineers will find this book helpful. Though complete beginners are welcome to read this book, some familiarity with core machine learning concepts will help readers maximize the benefits and insights gained from this comprehensive resource.Table of {ContentsIntroduction} to Data Imbalance in Machine {LearningOversampling} {MethodsUndersampling} {MethodsEnsemble} {MethodsCost}-Sensitive {LearningData} Imbalance in Deep {LearningData}-Level Deep Learning {MethodsAlgorithm}-Level Deep Learning {TechniquesHybrid} Deep Learning {MethodsModel} {CalibrationAppendix}},
	pagetotal = {344},
	publisher = {Packt Publishing},
	author = {Abhishek, Kumar and Abdelaziz, Dr Mounir},
	date = {2023-11-30},
}

@misc{he2023,
	title = {You Only Condense Once: Two Rules for Pruning Condensed Datasets},
	url = {http://arxiv.org/abs/2310.14019},
	shorttitle = {You Only Condense Once},
	abstract = {Dataset condensation is a crucial tool for enhancing training efficiency by reducing the size of the training dataset, particularly in on-device scenarios. However, these scenarios have two significant challenges: 1) the varying computational resources available on the devices require a dataset size different from the pre-defined condensed dataset, and 2) the limited computational resources often preclude the possibility of conducting additional condensation processes. We introduce You Only Condense Once ({YOCO}) to overcome these limitations. On top of one condensed dataset, {YOCO} produces smaller condensed datasets with two embarrassingly simple dataset pruning rules: Low {LBPE} Score and Balanced Construction. {YOCO} offers two key advantages: 1) it can flexibly resize the dataset to fit varying computational constraints, and 2) it eliminates the need for extra condensation processes, which can be computationally prohibitive. Experiments validate our findings on networks including {ConvNet}, {ResNet} and {DenseNet}, and datasets including {CIFAR}10, {CIFAR}-100 and {ImageNet}. For example, our {YOCO} surpassed various dataset condensation and dataset pruning methods on {CIFAR}-10 with ten Images Per Class ({IPC}), achieving 6.98-8.89\% and 6.31-23.92\% accuracy gains, respectively. The code is available at: github.com/he-y/you-only-condense-once.},
	number = {{arXiv}:2310.14019},
	publisher = {{arXiv}},
	author = {He, Yang and Xiao, Lingao and Zhou, Joey Tianyi},
	urldate = {2024-05-21},
	date = {2023-10-21},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2310.14019 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{chen2023,
	title = {Dataset Distillation via Adversarial Prediction Matching},
	url = {http://arxiv.org/abs/2312.08912},
	doi = {10.48550/arXiv.2312.08912},
	abstract = {Dataset distillation is the technique of synthesizing smaller condensed datasets from large original datasets while retaining necessary information to persist the effect. In this paper, we approach the dataset distillation problem from a novel perspective: we regard minimizing the prediction discrepancy on the real data distribution between models, which are respectively trained on the large original dataset and on the small distilled dataset, as a conduit for condensing information from the raw data into the distilled version. An adversarial framework is proposed to solve the problem efficiently. In contrast to existing distillation methods involving nested optimization or long-range gradient unrolling, our approach hinges on single-level optimization. This ensures the memory efficiency of our method and provides a flexible tradeoff between time and memory budgets, allowing us to distil {ImageNet}-1K using a minimum of only 6.5GB of {GPU} memory. Under the optimal tradeoff strategy, it requires only 2.5\${\textbackslash}times\$ less memory and 5\${\textbackslash}times\$ less runtime compared to the state-of-the-art. Empirically, our method can produce synthetic datasets just 10\% the size of the original, yet achieve, on average, 94\% of the test accuracy of models trained on the full original datasets including {ImageNet}-1K, significantly surpassing state-of-the-art. Additionally, extensive tests reveal that our distilled datasets excel in cross-architecture generalization capabilities.},
	number = {{arXiv}:2312.08912},
	publisher = {{arXiv}},
	author = {Chen, Mingyang and Huang, Bo and Lu, Junda and Li, Bing and Wang, Yi and Cheng, Minhao and Wang, Wei},
	urldate = {2024-05-21},
	date = {2023-12-14},
	eprinttype = {arxiv},
	eprint = {2312.08912 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{shorten2019,
	title = {A survey on {Image} {Data} {Augmentation} for {Deep} {Learning}},
	volume = {6},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0},
	doi = {10.1186/s40537-019-0197-0},
	language = {en},
	number = {1},
	urldate = {2024-07-18},
	journal = {Journal of Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	month = dec,
	year = {2019},
	pages = {60},
}

@inproceedings{simard1991,
	title = {Tangent Prop - A formalism for specifying selected invariances in an adaptive network},
	volume = {4},
	url = {proceedings.neurips.cc/paper/1991/hash/65658fde58ab3c2b6e5132a39fae7cb9-Abstract.html},
	abstract = {In many machine learning applications, one has access, not only to training  data, but also to some high-level a priori knowledge about the desired be(cid:173) havior of the system. For example, it is known in advance that the output  of a character recognizer should be invariant with respect to small spa(cid:173) tial distortions of the input images (translations, rotations, scale changes,  etcetera).  We have implemented a scheme that allows a network to learn the deriva(cid:173) tive of its outputs with respect to distortion operators of our choosing.  This not only reduces the learning time and the amount of training data,  but also provides a powerful language for specifying what generalizations  we wish the network to perform.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Morgan-Kaufmann},
	author = {Simard, Patrice and Victorri, Bernard and {LeCun}, Yann and Denker, John},
	urldate = {2024-05-21},
	year = {1991},
}

@inproceedings{yaeger1996,
        author = {Yaeger, Larry and Lyon, Richard and Webb, Brandyn},
        booktitle = {Advances in Neural Information Processing Systems},
        editor = {M.C. Mozer and M. Jordan and T. Petsche},
        pages = {},
        publisher = {MIT Press},
        title = {Effective Training of a Neural Network Character Classifier for Word Recognition},
        url = {https://proceedings.neurips.cc/paper_files/paper/1996/file/81e5f81db77c596492e6f1a5a792ed53-Paper.pdf},
        volume = {9},
        year = {1996},
	abstract = {We have combined an artificial neural network ({ANN}) character classifier with context-driven search over character segmentation, word segmentation, and word recognition hypotheses to provide robust recognition of hand-printed English text in new models of Apple Computer's Newton {MessagePad}. We present some innovations in the training and use of {ANNs} as character classifiers for word recognition, including normalized output error, frequency balancing, error emphasis, negative training, and stroke warping. A recurring theme of reducing a priori biases emerges and is discussed.},
	date = {1996-01-01},
}

@inproceedings{simard2003,
	title = {Best practices for convolutional neural networks applied to visual document analysis},
	url = {ieeexplore.ieee.org/document/1227801},
	doi = {10.1109/ICDAR.2003.1227801},
	eventtitle = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
	pages = {958--963},
	booktitle = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
	author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
	urldate = {2024-05-21},
	date = {2003-08},
	keywords = {Best practices, Concrete, Convolution, Handwriting recognition, Industrial training, Information processing, Neural networks, Performance analysis, Support vector machines, Text analysis},
}

@inproceedings{lecun1995,
        title = "Learning algorithms for classification: A comparison on handwritten digit recognition",
        author = "Yann Lecun and L.D. Jackel and Leon Bottou and Corinna Cortes and Denker, {J. S.} and Harris Drucker and I. Guyon and U.A. Muller and Eduard Sackinger and Patrice Simard and V. Vapnik",
        year = "1995",
        language = "English (US)",
        pages = "261--276",
        editor = "J.H. Oh and C. Kwon and S. Cho",
        booktitle = "Neural networks",
        publisher = "World Scientific",
}

@article{japkowicz2000,
	title = {The class imbalance problem: {Significance} and strategies},
	volume = {56},
	journal = {Proc. of the Int’l Conf. on artificial intelligence},
	author = {Japkowicz, Nathalie},
	month = jun,
	year = {2000},
	pages = {111--117},
}

@article{megahed2021,
	title = {The class imbalance problem},
	volume = {18},
	copyright = {2021 Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-021-01302-4},
	doi = {10.1038/s41592-021-01302-4},
	abstract = {The exception proves the rule.},
	language = {en},
	number = {11},
	urldate = {2024-05-21},
	journal = {Nature Methods},
	author = {Megahed, Fadel M. and Chen, Ying-Ju and Megahed, Aly and Ong, Yuya and Altman, Naomi and Krzywinski, Martin},
	month = nov,
	year = {2021},
	note = {Publisher: Nature Publishing Group},
	keywords = {Bioinformatics, Biological Microscopy, Biological Techniques, Biomedical Engineering/Biotechnology, Life Sciences, Proteomics, general},
	pages = {1270--1272},
}

@misc{ma2024,
	title = {Breaking the Barrier: Selective Uncertainty-based Active Learning for Medical Image Segmentation},
	url = {http://arxiv.org/abs/2401.16298},
	doi = {10.48550/arXiv.2401.16298},
	shorttitle = {Breaking the Barrier},
	abstract = {Active learning ({AL}) has found wide applications in medical image segmentation, aiming to alleviate the annotation workload and enhance performance. Conventional uncertainty-based {AL} methods, such as entropy and Bayesian, often rely on an aggregate of all pixel-level metrics. However, in imbalanced settings, these methods tend to neglect the significance of target regions, eg., lesions, and tumors. Moreover, uncertainty-based selection introduces redundancy. These factors lead to unsatisfactory performance, and in many cases, even underperform random sampling. To solve this problem, we introduce a novel approach called the Selective Uncertainty-based {AL}, avoiding the conventional practice of summing up the metrics of all pixels. Through a filtering process, our strategy prioritizes pixels within target areas and those near decision boundaries. This resolves the aforementioned disregard for target areas and redundancy. Our method showed substantial improvements across five different uncertainty-based methods and two distinct datasets, utilizing fewer labeled data to reach the supervised baseline and consistently achieving the highest overall performance. Our code is available at github.com/{HelenMa}9998/Selective{\textbackslash}\_Uncertainty{\textbackslash}\_AL.},
	number = {{arXiv}:2401.16298},
	publisher = {{arXiv}},
	author = {Ma, Siteng and Wu, Haochang and Lawlor, Aonghus and Dong, Ruihai},
	urldate = {2024-03-31},
	date = {2024-01-29},
	eprinttype = {arxiv},
	eprint = {2401.16298 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{dominguez-catena2024,
	title = {Metrics for Dataset Demographic Bias: A Case Study on Facial Expression Recognition},
	issn = {1939-3539},
	url = {ieeexplore.ieee.org/document/10420507},
	doi = {10.1109/TPAMI.2024.3361979},
	shorttitle = {Metrics for Dataset Demographic Bias},
	abstract = {Demographic biases in source datasets have been shown as one of the causes of unfairness and discrimination in the predictions of Machine Learning models. One of the most prominent types of demographic bias are statistical imbalances in the representation of demographic groups in the datasets. In this paper, we study the measurement of these biases by reviewing the existing metrics, including those that can be borrowed from other disciplines. We develop a taxonomy for the classification of these metrics, providing a practical guide for the selection of appropriate metrics. To illustrate the utility of our framework, and to further understand the practical characteristics of the metrics, we conduct a case study of 20 datasets used in Facial Emotion Recognition ({FER}), analyzing the biases present in them. Our experimental results show that many metrics are redundant and that a reduced subset of metrics may be sufficient to measure the amount of demographic bias. The paper provides valuable insights for researchers in {AI} and related fields to mitigate dataset bias and improve the fairness and accuracy of {AI} models. The code is available at github.com/irisdominguez/dataset\_bias\_metrics.},
	pages = {1--18},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Dominguez-Catena, Iris and Paternain, Daniel and Galar, Mikel},
	urldate = {2024-03-24},
	date = {2024},
	note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {{AI} fairness, Artificial intelligence, Data models, Face recognition, Mathematical models, Measurement, Taxonomy, Training, artificial intelligence, deep learning, demographic bias, facial expression recognition},
}

@article{sapsis2022,
	title = {Optimal criteria and their asymptotic form for data selection in data-driven reduced-order modelling with Gaussian process regression},
	volume = {380},
	issn = {1364-503X, 1471-2962},
	url = {royalsocietypublishing.org/doi/10.1098/rsta.2021.0197},
	doi = {10.1098/rsta.2021.0197},
	abstract = {We derive criteria for the selection of datapoints used for data-driven reduced-order modelling and other areas of supervised learning based on Gaussian process regression ({GPR}). While this is a well-studied area in the fields of active learning and optimal experimental design, most criteria in the literature are empirical. Here we introduce an optimality condition for the selection of a new input defined as the minimizer of the distance between the approximated output probability density function (pdf) of the reduced-order model and the exact one. Given that the exact pdf is unknown, we define the selection criterion as the supremum over the unit sphere of the native Hilbert space for the {GPR}. The resulting selection criterion, however, has a form that is difficult to compute. We combine results from {GPR} theory and asymptotic analysis to derive a computable form of the defined optimality criterion that is valid in the limit of small predictive variance. The derived asymptotic form of the selection criterion leads to convergence of the {GPR} model that guarantees a balanced distribution of data resources between probable and large-deviation outputs, resulting in an effective way of sampling towards data-driven reduced-order modelling.
            This article is part of the theme issue ‘Data-driven prediction in dynamical systems’.},
	pages = {20210197},
	number = {2229},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Phil. Trans. R. Soc. A.},
	author = {Sapsis, Themistoklis P. and Blanchard, Antoine},
	urldate = {2024-03-24},
	date = {2022-08-08},
	langid = {english},
	keywords = {sampling},
}

@article{ferryman2023,
	title = {Considering Biased Data as Informative Artifacts in {AI}-Assisted Health Care},
	volume = {389},
	issn = {0028-4793},
	url = {nejm.org/doi/10.1056/NEJMra2214964},
	doi = {10.1056/NEJMra2214964},
	pages = {833--838},
	number = {9},
	journaltitle = {New England Journal of Medicine},
	shortjournal = {N Engl J Med},
	author = {Ferryman, Kadija and Mackintosh, Maxine and Ghassemi, Marzyeh},
	urldate = {2023-09-14},
	date = {2023-08-31},
	note = {Publisher: Massachusetts Medical Society},
}

@misc{meng2021,
	title = {{MagFace}: A Universal Representation for Face Recognition and Quality Assessment},
	url = {ieeexplore.ieee.org/document/9578764/},
	doi = {10.1109/CVPR46437.2021.01400},
	shorttitle = {{MagFace}},
	abstract = {The performance of face recognition system degrades when the variability of the acquired faces increases. Prior work alleviates this issue by either monitoring the face quality in pre-processing or predicting the data uncertainty along with the face feature. This paper proposes {MagFace}, a category of losses that learn a universal feature embedding whose magnitude can measure the quality of the given face. Under the new loss, it can be proven that the magnitude of the feature embedding monotonically increases if the subject is more likely to be recognized. In addition, {MagFace} introduces an adaptive mechanism to learn a wellstructured within-class feature distributions by pulling easy samples to class centers while pushing hard samples away. This prevents models from overﬁtting on noisy low-quality samples and improves face recognition in the wild. Extensive experiments conducted on face recognition, quality assessments as well as clustering demonstrate its superiority over state-of-the-arts. The code is available at github.com/{IrvingMeng}/{MagFace}.},
	publisher = {{IEEE}},
	author = {Meng, Qiang and Zhao, Shichao and Huang, Zhida and Zhou, Feng},
	urldate = {2022-12-25},
	date = {2021-06},
	langid = {english},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{nissim2017,
	title = {Inter-labeler and intra-labeler variability of condition severity classification models using active and passive learning methods},
	volume = {81},
	issn = {1873-2860},
	doi = {10.1016/j.artmed.2017.03.003},
	abstract = {{BACKGROUND} {AND} {OBJECTIVES}: Labeling instances by domain experts for classification is often time consuming and expensive. To reduce such labeling efforts, we had proposed the application of active learning ({AL}) methods, introduced our {CAESAR}-{ALE} framework for classifying the severity of clinical conditions, and shown its significant reduction of labeling efforts. The use of any of three {AL} methods (one well known [{SVM}-Margin], and two that we introduced [Exploitation and Combination\_XA]) significantly reduced (by 48\% to 64\%) condition labeling efforts, compared to standard passive (random instance-selection) {SVM} learning. Furthermore, our new {AL} methods achieved maximal accuracy using 12\% fewer labeled cases than the {SVM}-Margin {AL} method. However, because labelers have varying levels of expertise, a major issue associated with learning methods, and {AL} methods in particular, is how to best to use the labeling provided by a committee of labelers. First, we wanted to know, based on the labelers' learning curves, whether using {AL} methods (versus standard passive learning methods) has an effect on the Intra-labeler variability (within the learning curve of each labeler) and inter-labeler variability (among the learning curves of different labelers). Then, we wanted to examine the effect of learning (either passively or actively) from the labels created by the majority consensus of a group of labelers.
{METHODS}: We used our {CAESAR}-{ALE} framework for classifying the severity of clinical conditions, the three {AL} methods and the passive learning method, as mentioned above, to induce the classifications models. We used a dataset of 516 clinical conditions and their severity labeling, represented by features aggregated from the medical records of 1.9 million patients treated at Columbia University Medical Center. We analyzed the variance of the classification performance within (intra-labeler), and especially among (inter-labeler) the classification models that were induced by using the labels provided by seven labelers. We also compared the performance of the passive and active learning models when using the consensus label.
{RESULTS}: The {AL} methods: produced, for the models induced from each labeler, smoother Intra-labeler learning curves during the training phase, compared to the models produced when using the passive learning method. The mean standard deviation of the learning curves of the three {AL} methods over all labelers (mean: 0.0379; range: [0.0182 to 0.0496]), was significantly lower (p=0.049) than the Intra-labeler standard deviation when using the passive learning method (mean: 0.0484; range: [0.0275-0.0724). Using the {AL} methods resulted in a lower mean Inter-labeler {AUC} standard deviation among the {AUC} values of the labelers' different models during the training phase, compared to the variance of the induced models' {AUC} values when using passive learning. The Inter-labeler {AUC} standard deviation, using the passive learning method (0.039), was almost twice as high as the Inter-labeler standard deviation using our two new {AL} methods (0.02 and 0.019, respectively). The {SVM}-Margin {AL} method resulted in an Inter-labeler standard deviation (0.029) that was higher by almost 50\% than that of our two {AL} methods The difference in the inter-labeler standard deviation between the passive learning method and the {SVM}-Margin learning method was significant (p=0.042). The difference between the {SVM}-Margin and Exploitation method was insignificant (p=0.29), as was the difference between the Combination\_XA and Exploitation methods (p=0.67). Finally, using the consensus label led to a learning curve that had a higher mean intra-labeler variance, but resulted eventually in an {AUC} that was at least as high as the {AUC} achieved using the gold standard label and that was always higher than the expected mean {AUC} of a randomly selected labeler, regardless of the choice of learning method (including a passive learning method). Using a paired t-test, the difference between the intra-labeler {AUC} standard deviation when using the consensus label, versus that value when using the other two labeling strategies, was significant only when using the passive learning method (p=0.014), but not when using any of the three {AL} methods.
{CONCLUSIONS}: The use of {AL} methods, (a) reduces intra-labeler variability in the performance of the induced models during the training phase, and thus reduces the risk of halting the process at a local minimum that is significantly different in performance from the rest of the learned models; and (b) reduces Inter-labeler performance variance, and thus reduces the dependence on the use of a particular labeler. In addition, the use of a consensus label, agreed upon by a rather uneven group of labelers, might be at least as good as using the gold standard labeler, who might not be available, and certainly better than randomly selecting one of the group's individual labelers. Finally, using the {AL} methods: when provided by the consensus label reduced the intra-labeler {AUC} variance during the learning phase, compared to using passive learning.},
	pages = {12--32},
	journaltitle = {Artificial Intelligence in Medicine},
	shortjournal = {Artif Intell Med},
	author = {Nissim, Nir and Shahar, Yuval and Elovici, Yuval and Hripcsak, George and Moskovitch, Robert},
	date = {2017-09},
	pmid = {28456512},
	pmcid = {PMC5937023},
	keywords = {Active learning, Area Under Curve, Condition, Data Mining, Electronic Health Records, Electronic health records, Humans, Labeling, Learning Curve, Observer Variation, Phenotype, Phenotyping, Reproducibility of Results, Severity, Severity of Illness Index, Supervised Machine Learning, Time Factors, Variance},
}

@misc{power2022,
	title = {Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets},
	url = {http://arxiv.org/abs/2201.02177},
	shorttitle = {Grokking},
	abstract = {In this paper we propose to study generalization of neural networks on small algorithmically generated datasets. In this setting, questions about data efﬁciency, memorization, generalization, and speed of learning can be studied in great detail. In some situations we show that neural networks learn through a process of “grokking” a pattern in the data, improving generalization performance from random chance level to perfect generalization, and that this improvement in generalization can happen well past the point of overﬁtting. We also study generalization as a function of dataset size and ﬁnd that smaller datasets require increasing amounts of optimization for generalization. We argue that these datasets provide a fertile ground for studying a poorly understood aspect of deep learning: generalization of overparametrized neural networks beyond memorization of the ﬁnite training dataset.},
	number = {{arXiv}:2201.02177},
	publisher = {{arXiv}},
	author = {Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
	urldate = {2022-08-27},
	date = {2022-01-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2201.02177 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{kim2017,
	title = {Exploiting Unlabeled Texts with Clustering-based Instance Selection for Medical Relation Classification},
	volume = {2017},
	issn = {1942-597X},
	abstract = {Classifying relations between pairs of medical concepts in clinical texts is a crucial task to acquire empirical evidence relevant to patient care. Due to limited labeled data and extremely unbalanced class distributions, medical relation classification systems struggle to achieve good performance on less common relation types, which capture valuable information that is important to identify. Our research aims to improve relation classification using weakly supervised learning. We present two clustering-based instance selection methods that acquire a diverse and balanced set of additional training instances from unlabeled data. The first method selects one representative instance from each cluster containing only unlabeled data. The second method selects a counterpart for each training instance using clusters containing both labeled and unlabeled data. These new instance selection methods for weakly supervised learning achieve substantial recall gains for the minority relation classes compared to supervised learning, while yielding comparable performance on the majority relation classes.},
	pages = {1060--1069},
	journaltitle = {{AMIA} ... Annual Symposium proceedings. {AMIA} Symposium},
	shortjournal = {{AMIA} Annu Symp Proc},
	author = {Kim, Youngjun and Riloff, Ellen and Meystre, Stéphane M.},
	date = {2017},
	pmid = {29854174},
	pmcid = {PMC5977715},
	keywords = {Algorithms, Cluster Analysis, Electronic Health Records, Humans, Information Storage and Retrieval, Natural Language Processing, Supervised Machine Learning, Vocabulary, Controlled},
}

@article{garcia-pedrajas2009,
	title = {Constructing ensembles of classifiers by means of weighted instance selection},
	volume = {20},
	issn = {1941-0093},
	doi = {10.1109/TNN.2008.2005496},
	abstract = {In this paper, we approach the problem of constructing ensembles of classifiers from the point of view of instance selection. Instance selection is aimed at obtaining a subset of the instances available for training capable of achieving, at least, the same performance as the whole training set. In this way, instance selection algorithms try to keep the performance of the classifiers while reducing the number of instances in the training set. Meanwhile, boosting methods construct an ensemble of classifiers iteratively focusing each new member on the most difficult instances by means of a biased distribution of the training instances. In this work, we show how these two methodologies can be combined advantageously. We can use instance selection algorithms for boosting using as objective to optimize the training error weighted by the biased distribution of the instances given by the boosting method. Our method can be considered as boosting by instance selection. Instance selection has mostly been developed and used for k -nearest neighbor ( k -{NN}) classifiers. So, as a first step, our methodology is suited to construct ensembles of k -{NN} classifiers. Constructing ensembles of classifiers by means of instance selection has the important feature of reducing the space complexity of the final ensemble as only a subset of the instances is selected for each classifier. However, the methodology is not restricted to k-{NN} classifier. Other classifiers, such as decision trees and support vector machines ({SVMs}), may also benefit from a smaller training set, as they produce simpler classifiers if an instance selection algorithm is performed before training. In the experimental section, we show that the proposed approach is able to produce better and simpler ensembles than random subspace method ({RSM}) method for k-{NN} and standard ensemble methods for C4.5 and {SVMs}.},
	pages = {258--277},
	number = {2},
	journaltitle = {{IEEE} transactions on neural networks},
	shortjournal = {{IEEE} Trans Neural Netw},
	author = {García-Pedrajas, Nicolás},
	date = {2009-02},
	pmid = {19179252},
	note = {Number: 2},
	keywords = {Algorithms, Pattern Recognition, Automated, Support Vector Machine},
}

@misc{wan2022,
	title = {A Survey of Data Optimization for Problems in Computer Vision Datasets},
	url = {http://arxiv.org/abs/2210.11717},
	abstract = {Recent years have witnessed remarkable progress in artificial intelligence ({AI}) thanks to refined deep network structures, powerful computing devices, and large-scale labeled datasets. However, researchers have mainly invested in the optimization of models and computational devices, leading to the fact that good models and powerful computing devices are currently readily available, while datasets are still stuck at the initial stage of large-scale but low quality. Data becomes a major obstacle to {AI} development. Taking note of this, we dig deeper and find that there has been some but unstructured work on data optimization. They focus on various problems in datasets and attempt to improve dataset quality by optimizing its structure to facilitate {AI} development. In this paper, we present the first review of recent advances in this area. First, we summarize and analyze various problems that exist in large-scale computer vision datasets. We then define data optimization and classify data optimization algorithms into three directions according to the optimization form: data sampling, data subset selection, and active learning. Next, we organize these data optimization works according to data problems addressed, and provide a systematic and comparative description. Finally, we summarize the existing literature and propose some potential future research topics.},
	number = {{arXiv}:2210.11717},
	publisher = {{arXiv}},
	author = {Wan, Zhijing and Wang, Zhixiang and Chung, {CheukTing} and Wang, Zheng},
	urldate = {2022-10-27},
	date = {2022-10-20},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2210.11717 [cs]},
	keywords = {A.1, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{zhan2022,
	title = {A Comparative Survey of Deep Active Learning},
	url = {http://arxiv.org/abs/2203.13450},
	abstract = {While deep learning ({DL}) is data-hungry and usually relies on extensive labeled data to deliver good performance, Active Learning ({AL}) reduces labeling costs by selecting a small proportion of samples from unlabeled data for labeling and training. Therefore, Deep Active Learning ({DAL}) has risen as a feasible solution for maximizing model performance under a limited labeling cost/budget in recent years. Although abundant methods of {DAL} have been developed and various literature reviews conducted, the performance evaluation of {DAL} methods under fair comparison settings is not yet available. Our work intends to fill this gap. In this work, We construct a {DAL} toolkit, {DeepAL}+, by re-implementing 19 highly-cited {DAL} methods. We survey and categorize {DAL}-related works and construct comparative experiments across frequently used datasets and {DAL} algorithms. Additionally, we explore some factors (e.g., batch size, number of epochs in the training process) that influence the efficacy of {DAL}, which provides better references for researchers to design their {DAL} experiments or carry out {DAL}-related applications.},
	number = {{arXiv}:2203.13450},
	publisher = {{arXiv}},
	author = {Zhan, Xueying and Wang, Qingzhong and Huang, Kuan-hao and Xiong, Haoyi and Dou, Dejing and Chan, Antoni B.},
	urldate = {2022-12-10},
	date = {2022-07-19},
	eprinttype = {arxiv},
	eprint = {2203.13450 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{baltruschat2019,
	title = {Comparison of Deep Learning Approaches for Multi-Label Chest X-Ray Classification},
	volume = {9},
	rights = {2019 The Author(s)},
	issn = {2045-2322},
	url = {nature.com/articles/s41598-019-42294-8},
	doi = {10.1038/s41598-019-42294-8},
	abstract = {The increased availability of labeled X-ray image archives (e.g. {ChestX}-ray14 dataset) has triggered a growing interest in deep learning techniques. To provide better insight into the different approaches, and their applications to chest X-ray classification, we investigate a powerful network architecture in detail: the {ResNet}-50. Building on prior work in this domain, we consider transfer learning with and without fine-tuning as well as the training of a dedicated X-ray network from scratch. To leverage the high spatial resolution of X-ray data, we also include an extended {ResNet}-50 architecture, and a network integrating non-image data (patient age, gender and acquisition type) in the classification process. In a concluding experiment, we also investigate multiple {ResNet} depths (i.e. {ResNet}-38 and {ResNet}-101). In a systematic evaluation, using 5-fold re-sampling and a multi-label loss function, we compare the performance of the different approaches for pathology classification by {ROC} statistics and analyze differences between the classifiers using rank correlation. Overall, we observe a considerable spread in the achieved performance and conclude that the X-ray-specific {ResNet}-38, integrating non-image data yields the best overall results. Furthermore, class activation maps are used to understand the classification process, and a detailed analysis of the impact of non-image features is provided.},
	pages = {6381},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Baltruschat, Ivo M. and Nickisch, Hannes and Grass, Michael and Knopp, Tobias and Saalbach, Axel},
	urldate = {2023-05-11},
	date = {2019-04-23},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational science, Pathology, Radiography},
}

@misc{valavi2022,
	title = {Time and the Value of Data},
	url = {http://arxiv.org/abs/2203.09118},
	doi = {10.48550/arXiv.2203.09118},
	abstract = {Managers often believe that collecting more data will continually improve the accuracy of their machine learning models. However, we argue in this paper that when data lose relevance over time, it may be optimal to collect a limited amount of recent data instead of keeping around an infinite supply of older (less relevant) data. In addition, we argue that increasing the stock of data by including older datasets may, in fact, damage the model's accuracy. Expectedly, the model's accuracy improves by increasing the flow of data (defined as data collection rate); however, it requires other tradeoffs in terms of refreshing or retraining machine learning models more frequently. Using these results, we investigate how the business value created by machine learning models scales with data and when the stock of data establishes a sustainable competitive advantage. We argue that data's time-dependency weakens the barrier to entry that the stock of data creates. As a result, a competing firm equipped with a limited (yet sufficient) amount of recent data can develop more accurate models. This result, coupled with the fact that older datasets may deteriorate models' accuracy, suggests that created business value doesn't scale with the stock of available data unless the firm offloads less relevant data from its data repository. Consequently, a firm's growth policy should incorporate a balance between the stock of historical data and the flow of new data. We complement our theoretical results with an experiment. In the experiment, we empirically measure the loss in the accuracy of a next word prediction model trained on datasets from various time periods. Our empirical measurements confirm the economic significance of the value decline over time. For example, 100MB of text data, after seven years, becomes as valuable as 50MB of current data for the next word prediction task.},
	number = {{arXiv}:2203.09118},
	publisher = {{arXiv}},
	author = {Valavi, Ehsan and Hestness, Joel and Ardalani, Newsha and Iansiti, Marco},
	urldate = {2022-12-10},
	date = {2022-03-17},
	eprinttype = {arxiv},
	eprint = {2203.09118 [cs, econ, q-fin]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Economics - General Economics},
}

@misc{appalaraju2018,
	title = {Image similarity using Deep {CNN} and Curriculum Learning},
	url = {http://arxiv.org/abs/1709.08761},
	abstract = {Image similarity involves fetching similar looking images given a reference image. Our solution called {SimNet}, is a deep siamese network which is trained on pairs of positive and negative images using a novel online pair mining strategy inspired by Curriculum learning. We also created a multi-scale {CNN}, where the final image embedding is a joint representation of top as well as lower layer embedding's. We go on to show that this multi-scale siamese network is better at capturing fine grained image similarities than traditional {CNN}'s.},
	number = {{arXiv}:1709.08761},
	publisher = {{arXiv}},
	author = {Appalaraju, Srikar and Chaoji, Vineet},
	urldate = {2022-12-10},
	date = {2018-07-13},
	eprinttype = {arxiv},
	eprint = {1709.08761 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{gildenblat2020,
	title = {Self-Supervised Similarity Learning for Digital Pathology},
	url = {http://arxiv.org/abs/1905.08139},
	abstract = {Using features extracted from networks pretrained on {ImageNet} is a common practice in applications of deep learning for digital pathology. However it presents the downside of missing domain specific image information. In digital pathology, supervised training data is expensive and difficult to collect. We propose a self-supervised method for feature extraction by similarity learning on whole slide images ({WSI}) that is simple to implement and allows creation of robust and compact image descriptors. We train a siamese network, exploiting image spatial continuity and assuming spatially adjacent tiles in the image are more similar to each other than distant tiles. Our network outputs feature vectors of length 128, which allows dramatically lower memory storage and faster processing than networks pretrained on {ImageNet}. We apply the method on digital pathology {WSIs} from the Camelyon16 train set and assess and compare our method by measuring image retrieval of tumor tiles and descriptor pair distance ratio for distant/near tiles in the Camelyon16 test set. We show that our method yields better retrieval task results than existing {ImageNet} based and generic self-supervised feature extraction methods. To the best of our knowledge, this is also the first published method for self-supervised learning tailored for digital pathology.},
	number = {{arXiv}:1905.08139},
	publisher = {{arXiv}},
	author = {Gildenblat, Jacob and Klaiman, Eldad},
	urldate = {2022-12-10},
	date = {2020-01-13},
	eprinttype = {arxiv},
	eprint = {1905.08139 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{paiva2022,
	title = {Relating instance hardness to classification performance in a dataset: a visual approach},
	volume = {111},
	issn = {1573-0565},
	shorttitle = {Relating instance hardness to classification performance in a dataset},
	url = {https://doi.org/10.1007/s10994-022-06205-9},
	doi = {10.1007/s10994-022-06205-9},
	abstract = {Machine Learning studies often involve a series of computational experiments in which the predictive performance of multiple models are compared across one or more datasets. The results obtained are usually summarized through average statistics, either in numeric tables or simple plots. Such approaches fail to reveal interesting subtleties about algorithmic performance, including which observations an algorithm may find easy or hard to classify, and also which observations within a dataset may present unique challenges. Recently, a methodology known as Instance Space Analysis was proposed for visualizing algorithm performance across different datasets. This methodology relates predictive performance to estimated instance hardness measures extracted from the datasets. However, the analysis considered an instance as being an entire classification dataset and the algorithm performance was reported for each dataset as an average error across all observations in the dataset. In this paper, we developed a more fine-grained analysis by adapting the ISA methodology. The adapted version of ISA allows the analysis of an individual classification dataset by a 2-D hardness embedding, which provides a visualization of the data according to the difficulty level of its individual observations. This allows deeper analyses of the relationships between instance hardness and predictive performance of classifiers. We also provide an open-access Python package named PyHard, which encapsulates the adapted ISA and provides an interactive visualization interface. We illustrate through case studies how our tool can provide insights about data quality and algorithm performance in the presence of challenges such as noisy and biased data.},
	language = {en},
	number = {8},
	urldate = {2022-11-09},
	journal = {Machine Learning},
	author = {Paiva, Pedro Yuri Arbs and Moreno, Camila Castro and Smith-Miles, Kate and Valeriano, Maria Gabriela and Lorena, Ana Carolina},
	month = aug,
	year = {2022},
	keywords = {Classification performance, Hardness embedding, Instance hardness, Meta-learning},
	pages = {3085--3123},
}

@misc{chen2018,
	title = {Deep Generative Models in the Real-World: An Open Challenge from Medical Imaging},
	url = {http://arxiv.org/abs/1806.05452},
	shorttitle = {Deep Generative Models in the Real-World},
	abstract = {Recent advances in deep learning led to novel generative modeling techniques that achieve unprecedented quality in generated samples and performance in learning complex distributions in imaging data. These new models in medical image computing have important applications that form clinically relevant and very challenging unsupervised learning problems. In this paper, we explore the feasibility of using state-of-the-art auto-encoder-based deep generative models, such as variational and adversarial auto-encoders, for one such task: abnormality detection in medical imaging. We utilize typical, publicly available datasets with brain scans from healthy subjects and patients with stroke lesions and brain tumors. We use the data from healthy subjects to train different auto-encoder based models to learn the distribution of healthy images and detect pathologies as outliers. Models that can better learn the data distribution should be able to detect outliers more accurately. We evaluate the detection performance of deep generative models and compare them with non-deep learning based approaches to provide a benchmark of the current state of research. We conclude that abnormality detection is a challenging task for deep generative models and large room exists for improvement. In order to facilitate further research, we aim to provide carefully pre-processed imaging data available to the research community.},
	number = {{arXiv}:1806.05452},
	publisher = {{arXiv}},
	author = {Chen, Xiaoran and Pawlowski, Nick and Rajchl, Martin and Glocker, Ben and Konukoglu, Ender},
	urldate = {2022-10-31},
	date = {2018-06-14},
	eprinttype = {arxiv},
	eprint = {1806.05452 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{mishra2021,
	title = {Image Complexity Guided Network Compression for Biomedical Image Segmentation},
	url = {http://arxiv.org/abs/2107.02927},
	abstract = {Compression is a standard procedure for making convolutional neural networks ({CNNs}) adhere to some specific computing resource constraints. However, searching for a compressed architecture typically involves a series of time-consuming training/validation experiments to determine a good compromise between network size and performance accuracy. To address this, we propose an image complexity-guided network compression technique for biomedical image segmentation. Given any resource constraints, our framework utilizes data complexity and network architecture to quickly estimate a compressed model which does not require network training. Specifically, we map the dataset complexity to the target network accuracy degradation caused by compression. Such mapping enables us to predict the final accuracy for different network sizes, based on the computed dataset complexity. Thus, one may choose a solution that meets both the network size and segmentation accuracy requirements. Finally, the mapping is used to determine the convolutional layer-wise multiplicative factor for generating a compressed network. We conduct experiments using 5 datasets, employing 3 commonly-used {CNN} architectures for biomedical image segmentation as representative networks. Our proposed framework is shown to be effective for generating compressed segmentation networks, retaining up to \${\textbackslash}approx 95{\textbackslash}\%\$ of the full-sized network segmentation accuracy, and at the same time, utilizing \${\textbackslash}approx 32x\$ fewer network trainable weights (average reduction) of the full-sized networks.},
	number = {{arXiv}:2107.02927},
	publisher = {{arXiv}},
	author = {Mishra, Suraj and Chen, Danny Z. and Hu, X. Sharon},
	urldate = {2022-10-13},
	date = {2021-07-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2107.02927 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@misc{holland2018,
	title = {The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards},
	url = {http://arxiv.org/abs/1805.03677},
	doi = {10.48550/arXiv.1805.03677},
	shorttitle = {The Dataset Nutrition Label},
	abstract = {Artificial intelligence ({AI}) systems built on incomplete or biased data will often exhibit problematic outcomes. Current methods of data analysis, particularly before model development, are costly and not standardized. The Dataset Nutrition Label (the Label) is a diagnostic framework that lowers the barrier to standardized data analysis by providing a distilled yet comprehensive overview of dataset "ingredients" before {AI} model development. Building a Label that can be applied across domains and data types requires that the framework itself be flexible and adaptable; as such, the Label is comprised of diverse qualitative and quantitative modules generated through multiple statistical and probabilistic modelling backends, but displayed in a standardized format. To demonstrate and advance this concept, we generated and published an open source prototype with seven sample modules on the {ProPublica} Dollars for Docs dataset. The benefits of the Label are manyfold. For data specialists, the Label will drive more robust data analysis practices, provide an efficient way to select the best dataset for their purposes, and increase the overall quality of {AI} models as a result of more robust training datasets and the ability to check for issues at the time of model development. For those building and publishing datasets, the Label creates an expectation of explanation, which will drive better data collection practices. We also explore the limitations of the Label, including the challenges of generalizing across diverse datasets, and the risk of using "ground truth" data as a comparison dataset. We discuss ways to move forward given the limitations identified. Lastly, we lay out future directions for the Dataset Nutrition Label project, including research and public policy agendas to further advance consideration of the concept.},
	number = {{arXiv}:1805.03677},
	publisher = {{arXiv}},
	author = {Holland, Sarah and Hosny, Ahmed and Newman, Sarah and Joseph, Joshua and Chmielinski, Kasia},
	urldate = {2022-10-03},
	date = {2018-05-09},
	eprinttype = {arxiv},
	eprint = {1805.03677 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Databases},
}

@inproceedings{aggarwal2020,
	location = {Snowmass Village, {CO}, {USA}},
	title = {Active Learning for Imbalanced Datasets},
	isbn = {978-1-72816-553-0},
	url = {ieeexplore.ieee.org/document/9093475/},
	doi = {10.1109/WACV45572.2020.9093475},
	abstract = {Active learning increases the effectiveness of labeling when only subsets of unlabeled datasets can be processed manually. To our knowledge, existing algorithms are designed under the assumption that datasets are balanced. However, many real-life datasets are actually imbalanced and we propose two adaptations of active learning to tackle imbalance. First, we modify acquisition functions to select samples by taking advantage of a deep model pretrained on a source domain. Second, we introduce a balancing step in the acquisition process to reduce the imbalance of the labeled subset. Evaluation is done with four imbalanced datasets using existing active learning methods and their modiﬁcations introduced here. Results show that our adaptations are useful as long as knowledge from the source domain is transferable to target domains.},
	eventtitle = {2020 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})},
	pages = {1417--1426},
	booktitle = {2020 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})},
	publisher = {{IEEE}},
	author = {Aggarwal, Umang and Popescu, Adrian and Hudelot, Celine},
	urldate = {2022-09-20},
	date = {2020-03},
        year = {2020},
	langid = {english},
}

@misc{ozsoy2022,
	title = {Self-Supervised Learning with an Information Maximization Criterion},
	url = {http://arxiv.org/abs/2209.07999},
	abstract = {Self-supervised learning allows {AI} systems to learn effective representations from large amounts of data using tasks that do not require costly labeling. Mode collapse, i.e., the model producing identical representations for all inputs, is a central problem to many self-supervised learning approaches, making self-supervised tasks, such as matching distorted variants of the inputs, ineffective. In this article, we argue that a straightforward application of information maximization among alternative latent representations of the same input naturally solves the collapse problem and achieves competitive empirical results. We propose a self-supervised learning method, {CorInfoMax}, that uses a second-order statistics-based mutual information measure that reflects the level of correlation among its arguments. Maximizing this correlative information measure between alternative representations of the same input serves two purposes: (1) it avoids the collapse problem by generating feature vectors with non-degenerate covariances; (2) it establishes relevance among alternative representations by increasing the linear dependence among them. An approximation of the proposed information maximization objective simplifies to a Euclidean distance-based objective function regularized by the log-determinant of the feature covariance matrix. The regularization term acts as a natural barrier against feature space degeneracy. Consequently, beyond avoiding complete output collapse to a single point, the proposed approach also prevents dimensional collapse by encouraging the spread of information across the whole feature space. Numerical experiments demonstrate that {CorInfoMax} achieves better or competitive performance results relative to the state-of-the-art {SSL} approaches.},
	number = {{arXiv}:2209.07999},
	publisher = {{arXiv}},
	author = {Ozsoy, Serdar and Hamdan, Shadi and Arik, Sercan Ö and Yuret, Deniz and Erdogan, Alper T.},
	urldate = {2022-09-19},
	date = {2022-09-16},
	eprinttype = {arxiv},
	eprint = {2209.07999 [cs, eess, math]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Information Theory, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, I.2, I.4, I.5},
}

@online{patil2019,
	title = {Understanding {FAISS}},
	url = {towardsdatascience.com/understanding-faiss-619bb6db2d1a},
	abstract = {….And the world of Similarity Searching},
	titleaddon = {Medium},
	author = {Patil, Vedashree},
	urldate = {2022-08-26},
	date = {2019-08-14},
	langid = {english},
}

@misc{zhang2020,
	title = {Self-Supervised Visual Representation Learning from Hierarchical Grouping},
	url = {http://arxiv.org/abs/2012.03044},
	abstract = {We create a framework for bootstrapping visual representation learning from a primitive visual grouping capability. We operationalize grouping via a contour detector that partitions an image into regions, followed by merging of those regions into a tree hierarchy. A small supervised dataset suffices for training this grouping primitive. Across a large unlabeled dataset, we apply this learned primitive to automatically predict hierarchical region structure. These predictions serve as guidance for self-supervised contrastive feature learning: we task a deep network with producing per-pixel embeddings whose pairwise distances respect the region hierarchy. Experiments demonstrate that our approach can serve as state-of-the-art generic pre-training, benefiting downstream tasks. We additionally explore applications to semantic region search and video-based object instance tracking.},
	number = {{arXiv}:2012.03044},
	publisher = {{arXiv}},
	author = {Zhang, Xiao and Maire, Michael},
	urldate = {2022-08-26},
	date = {2020-12-05},
	eprinttype = {arxiv},
	eprint = {2012.03044 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{bi2021,
	title = {Instance Selection-Based Surrogate-Assisted Genetic Programming for Feature Learning in Image Classification},
	issn = {2168-2267, 2168-2275},
	url = {ieeexplore.ieee.org/document/9526355/},
	doi = {10.1109/TCYB.2021.3105696},
	pages = {1--15},
	journaltitle = {{IEEE} Transactions on Cybernetics},
	shortjournal = {{IEEE} Trans. Cybern.},
	author = {Bi, Ying and Xue, Bing and Zhang, Mengjie},
	urldate = {2022-08-18},
	date = {2021},
}

@misc{nguyen2019,
	title = {A Bayesian Perspective of Convolutional Neural Networks through a Deconvolutional Generative Model},
	url = {http://arxiv.org/abs/1811.02657},
	abstract = {Inspired by the success of Convolutional Neural Networks ({CNNs}) for supervised prediction in images, we design the Deconvolutional Generative Model ({DGM}), a new probabilistic generative model whose inference calculations correspond to those in a given {CNN} architecture. The {DGM} uses a {CNN} to design the prior distribution in the probabilistic model. Furthermore, the {DGM} generates images from coarse to finer scales. It introduces a small set of latent variables at each scale, and enforces dependencies among all the latent variables via a conjugate prior distribution. This conjugate prior yields a new regularizer based on paths rendered in the generative model for training {CNNs}-the Rendering Path Normalization ({RPN}). We demonstrate that this regularizer improves generalization, both in theory and in practice. In addition, likelihood estimation in the {DGM} yields training losses for {CNNs}, and inspired by this, we design a new loss termed as the Max-Min cross entropy which outperforms the traditional cross-entropy loss for object classification. The Max-Min cross entropy suggests a new deep network architecture, namely the Max-Min network, which can learn from less labeled data while maintaining good prediction performance. Our experiments demonstrate that the {DGM} with the {RPN} and the Max-Min architecture exceeds or matches the-state-of-art on benchmarks including {SVHN}, {CIFAR}10, and {CIFAR}100 for semi-supervised and supervised learning tasks.},
	number = {{arXiv}:1811.02657},
	publisher = {{arXiv}},
	author = {Nguyen, Tan and Ho, Nhat and Patel, Ankit and Anandkumar, Anima and Jordan, Michael I. and Baraniuk, Richard G.},
	urldate = {2022-08-19},
	date = {2019-12-09},
	eprinttype = {arxiv},
	eprint = {1811.02657 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{fan2021,
	title = {Unsupervised Visual Representation Learning via Dual-Level Progressive Similar Instance Selection},
	issn = {2168-2267, 2168-2275},
	url = {ieeexplore.ieee.org/document/9376704/},
	doi = {10.1109/TCYB.2021.3054978},
	pages = {1--11},
	journaltitle = {{IEEE} Transactions on Cybernetics},
	shortjournal = {{IEEE} Trans. Cybern.},
	author = {Fan, Hehe and Liu, Ping and Xu, Mingliang and Yang, Yi},
	urldate = {2022-08-18},
	date = {2021},
}

@article{garcia-pedrajas2014,
	title = {A scalable memetic algorithm for simultaneous instance and feature selection},
	volume = {22},
	issn = {1530-9304},
	doi = {10.1162/EVCO_a_00102},
	abstract = {Instance selection is becoming increasingly relevant due to the huge amount of data that is constantly produced in many fields of research. At the same time, most of the recent pattern recognition problems involve highly complex datasets with a large number of possible explanatory variables. For many reasons, this abundance of variables significantly harms classification or recognition tasks. There are efficiency issues, too, because the speed of many classification algorithms is largely improved when the complexity of the data is reduced. One of the approaches to address problems that have too many features or instances is feature or instance selection, respectively. Although most methods address instance and feature selection separately, both problems are interwoven, and benefits are expected from facing these two tasks jointly. This paper proposes a new memetic algorithm for dealing with many instances and many features simultaneously by performing joint instance and feature selection. The proposed method performs four different local search procedures with the aim of obtaining the most relevant subsets of instances and features to perform an accurate classification. A new fitness function is also proposed that enforces instance selection but avoids putting too much pressure on removing features. We prove experimentally that this fitness function improves the results in terms of testing error. Regarding the scalability of the method, an extension of the stratification approach is developed for simultaneous instance and feature selection. This extension allows the application of the proposed algorithm to large datasets. An extensive comparison using 55 medium to large datasets from the {UCI} Machine Learning Repository shows the usefulness of our method. Additionally, the method is applied to 30 large problems, with very good results. The accuracy of the method for class-imbalanced problems in a set of 40 datasets is shown. The usefulness of the method is also tested using decision trees and support vector machines as classification methods.},
	pages = {1--45},
	number = {1},
	journaltitle = {Evolutionary Computation},
	shortjournal = {Evol Comput},
	author = {García-Pedrajas, Nicolás and de Haro-García, Aida and Pérez-Rodríguez, Javier},
	date = {2014},
	pmid = {23544367},
	keywords = {Algorithms, Classification, Computer Simulation, Computing Methodologies, Decision Trees, Pattern Recognition, Automated, Search Engine, Support Vector Machine},
}

@article{derrac2012,
	title = {Integrating instance selection, instance weighting, and feature weighting for nearest neighbor classifiers by coevolutionary algorithms},
	volume = {42},
	issn = {1941-0492},
	doi = {10.1109/TSMCB.2012.2191953},
	abstract = {Cooperative coevolution is a successful trend of evolutionary computation which allows us to define partitions of the domain of a given problem, or to integrate several related techniques into one, by the use of evolutionary algorithms. It is possible to apply it to the development of advanced classification methods, which integrate several machine learning techniques into a single proposal. A novel approach integrating instance selection, instance weighting, and feature weighting into the framework of a coevolutionary model is presented in this paper. We compare it with a wide range of evolutionary and nonevolutionary related methods, in order to show the benefits of the employment of coevolution to apply the techniques considered simultaneously. The results obtained, contrasted through nonparametric statistical tests, show that our proposal outperforms other methods in the comparison, thus becoming a suitable tool in the task of enhancing the nearest neighbor classifier.},
	pages = {1383--1397},
	number = {5},
	journaltitle = {{IEEE} transactions on systems, man, and cybernetics. Part B, Cybernetics: a publication of the {IEEE} Systems, Man, and Cybernetics Society},
	shortjournal = {{IEEE} Trans Syst Man Cybern B Cybern},
	author = {Derrac, Joaquín and Triguero, Isaac and Garcia, Salvador and Herrera, Francisco},
	date = {2012-10},
	pmid = {22531787},
	keywords = {Algorithms, Artificial Intelligence, Computer Simulation, Decision Support Techniques, Models, Theoretical, Pattern Recognition, Automated},
}

@article{mazurowski2011,
	title = {Comparative analysis of instance selection algorithms for instance-based classifiers in the context of medical decision support},
	volume = {56},
	issn = {1361-6560},
	doi = {10.1088/0031-9155/56/2/012},
	abstract = {When constructing a pattern classifier, it is important to make best use of the instances (a.k.a. cases, examples, patterns or prototypes) available for its development. In this paper we present an extensive comparative analysis of algorithms that, given a pool of previously acquired instances, attempt to select those that will be the most effective to construct an instance-based classifier in terms of classification performance, time efficiency and storage requirements. We evaluate seven previously proposed instance selection algorithms and compare their performance to simple random selection of instances. We perform the evaluation using k-nearest neighbor classifier and three classification problems: one with simulated Gaussian data and two based on clinical databases for breast cancer detection and diagnosis, respectively. Finally, we evaluate the impact of the number of instances available for selection on the performance of the selection algorithms and conduct initial analysis of the selected instances. The experiments show that for all investigated classification problems, it was possible to reduce the size of the original development dataset to less than 3\% of its initial size while maintaining or improving the classification performance. Random mutation hill climbing emerges as the superior selection algorithm. Furthermore, we show that some previously proposed algorithms perform worse than random selection. Regarding the impact of the number of instances available for the classifier development on the performance of the selection algorithms, we confirm that the selection algorithms are generally more effective as the pool of available instances increases. In conclusion, instance selection is generally beneficial for instance-based classifiers as it can improve their performance, reduce their storage requirements and improve their response time. However, choosing the right selection algorithm is crucial.},
	pages = {473--489},
	number = {2},
	journaltitle = {Physics in Medicine and Biology},
	shortjournal = {Phys Med Biol},
	author = {Mazurowski, Maciej A. and Malof, Jordan M. and Tourassi, Georgia D.},
	date = {2011-01-21},
	pmid = {21191152},
	keywords = {Algorithms, Breast Neoplasms, Databases, Factual, Decision Support Systems, Clinical, Humans, Mammography, Pattern Recognition, Automated, Radiographic Image Interpretation, Computer-Assisted},
}

@article{garcia-pedrajas2013,
	title = {{OligoIS}: Scalable Instance Selection for Class-Imbalanced Data Sets},
	volume = {43},
	issn = {2168-2275},
	doi = {10.1109/TSMCB.2012.2206381},
	shorttitle = {{OligoIS}},
	abstract = {In current research, an enormous amount of information is constantly being produced, which poses a challenge for data mining algorithms. Many of the problems in extremely active research areas, such as bioinformatics, security and intrusion detection, or text mining, share the following two features: large data sets and class-imbalanced distribution of samples. Although many methods have been proposed for dealing with class-imbalanced data sets, most of these methods are not scalable to the very large data sets common to those research fields. In this paper, we propose a new approach to dealing with the class-imbalance problem that is scalable to data sets with many millions of instances and hundreds of features. This proposal is based on the divide-and-conquer principle combined with application of the selection process to balanced subsets of the whole data set. This divide-and-conquer principle allows the execution of the algorithm in linear time. Furthermore, the proposed method is easy to implement using a parallel environment and can work without loading the whole data set into memory. Using 40 class-imbalanced medium-sized data sets, we will demonstrate our method's ability to improve the results of state-of-the-art instance selection methods for class-imbalanced data sets. Using three very large data sets, we will show the scalability of our proposal to millions of instances and hundreds of features.},
	pages = {332--346},
	number = {1},
	journaltitle = {{IEEE} transactions on cybernetics},
	shortjournal = {{IEEE} Trans Cybern},
	author = {García-Pedrajas, Nicolás and Perez-Rodríguez, Javier and de Haro-García, Aida},
	date = {2013-02},
	pmid = {22868583},
}

@article{fu2011,
	title = {{MILIS}: multiple instance learning with instance selection},
	volume = {33},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2010.155},
	shorttitle = {{MILIS}},
	abstract = {Multiple instance learning ({MIL}) is a paradigm in supervised learning that deals with the classification of collections of instances called bags. Each bag contains a number of instances from which features are extracted. The complexity of {MIL} is largely dependent on the number of instances in the training data set. Since we are usually confronted with a large instance space even for moderately sized real-world data sets applications, it is important to design efficient instance selection techniques to speed up the training process without compromising the performance. In this paper, we address the issue of instance selection in {MIL}. We propose {MILIS}, a novel {MIL} algorithm based on adaptive instance selection. We do this in an alternating optimization framework by intertwining the steps of instance selection and classifier learning in an iterative manner which is guaranteed to converge. Initial instance selection is achieved by a simple yet effective kernel density estimator on the negative instances. Experimental results demonstrate the utility and efficiency of the proposed approach as compared to the state of the art.},
	pages = {958--977},
	number = {5},
	journaltitle = {{IEEE} transactions on pattern analysis and machine intelligence},
	shortjournal = {{IEEE} Trans Pattern Anal Mach Intell},
	author = {Fu, Zhouyu and Robles-Kelly, Antonio and Zhou, Jun},
	date = {2011-05},
	pmid = {20733226},
}

@article{marchiori2010,
	title = {Class conditional nearest neighbor for large margin instance selection},
	volume = {32},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2009.164},
	abstract = {This paper presents a relational framework for studying properties of labeled data points related to proximity and labeling information in order to improve the performance of the 1NN rule. Specifically, the class conditional nearest neighbor (ccnn) relation over pairs of points in a labeled training set is introduced. For a given class label c, this relation associates to each point a its nearest neighbor computed among only those points with class label c (excluded a). A characterization of ccnn in terms of two graphs is given. These graphs are used for defining a novel scoring function over instances by means of an information-theoretic divergence measure applied to the degree distributions of these graphs. The scoring function is employed to develop an effective large margin instance selection method, which is empirically demonstrated to improve storage and accuracy performance of the 1NN rule on artificial and real-life data sets.},
	pages = {364--370},
	number = {2},
	journaltitle = {{IEEE} transactions on pattern analysis and machine intelligence},
	shortjournal = {{IEEE} Trans Pattern Anal Mach Intell},
	author = {Marchiori, Elena},
	date = {2010-02},
	pmid = {20075464},
}

@article{chen2006,
	title = {{MILES}: multiple-instance learning via embedded instance selection},
	volume = {28},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2006.248},
	shorttitle = {{MILES}},
	abstract = {Multiple-instance problems arise from the situations where training class labels are attached to sets of samples (named bags), instead of individual samples within each bag (called instances). Most previous multiple-instance learning ({MIL}) algorithms are developed based on the assumption that a bag is positive if and only if at least one of its instances is positive. Although the assumption works well in a drug activity prediction problem, it is rather restrictive for other applications, especially those in the computer vision area. We propose a learning method, {MILES} (Multiple-Instance Learning via Embedded instance Selection), which converts the multiple-instance learning problem to a standard supervised learning problem that does not impose the assumption relating instance labels to bag labels. {MILES} maps each bag into a feature space defined by the instances in the training bags via an instance similarity measure. This feature mapping often provides a large number of redundant or irrelevant features. Hence, 1-norm {SVM} is applied to select important features as well as construct classifiers simultaneously. We have performed extensive experiments. In comparison with other methods, {MILES} demonstrates competitive classification accuracy, high computation efficiency, and robustness to labeling uncertainty.},
	pages = {1931--1947},
	number = {12},
	journaltitle = {{IEEE} transactions on pattern analysis and machine intelligence},
	shortjournal = {{IEEE} Trans Pattern Anal Mach Intell},
	author = {Chen, Yixin and Bi, Jinbo and Wang, James Z.},
	date = {2006-12},
	pmid = {17108368},
	keywords = {Algorithms, Artificial Intelligence, Image Enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, Information Storage and Retrieval, Reproducibility of Results, Sensitivity and Specificity},
}

@inproceedings{ojima2021,
	title = {Model-based Data-Complexity Estimator for Deep Learning Systems},
	url = {ieeexplore.ieee.org/document/9564363},
	doi = {10.1109/AITEST52744.2021.00011},
	abstract = {Verification of deep learning ({DL}) systems in various situations is growing in importance as they are being used in wider areas than ever before. To prevent unintentional behavior of a {DL} system, it is important to feed an unfamiliar input to simulate situations in which a model in the {DL} system can behave abnormally. Such an input is different from outliers since we consider only statistical characteristics to detect outliers and the response of the model is not taken into account. This paper proposes a method of evaluating a complexity of an input without a label for a given trained model for analyzing a dataset to find inputs unfamiliar to the model and estimating the similarity between two datasets. Specifically, we use an output of neurons in the model as an embedded representation of data. We regard typical patterns in the representations of data in a training dataset as features the model obtained from the training dataset. We then calculate a complexity of an input as a distance between the representation of the input and combination of the features. The obtained complexity can be applied for multiple purposes such as test guiding by extracting inputs that are complex for the model from a dataset, analyzing a training dataset to find an inappropriate input, and measuring the similarity between two datasets using complexity distribution. Experimental evaluations showed the effectiveness of the complexity calculated using the proposed method in analyzing a dataset.},
	eventtitle = {2021 {IEEE} International Conference on Artificial Intelligence Testing ({AITest})},
	pages = {1--8},
	booktitle = {2021 {IEEE} International Conference on Artificial Intelligence Testing ({AITest})},
	author = {Ojima, Yuta and Horiuchi, Shingo and Ishikawa, Fuyuki},
	urldate = {2024-05-22},
	date = {2021-08},
        year = {2021},
	keywords = {Analytical models, Data models, Dataset Evaluation, Deep Learning Systems, Deep learning, Feature Extraction, Feature extraction, Learning systems, Neurons, Test guiding, Training, Unsupervised},
}


@article{cho2021,
	title = {Data {Quality} {Measures} and {Efficient} {Evaluation} {Algorithms} for {Large}-{Scale} {High}-{Dimensional} {Data}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/11/2/472},
	doi = {10.3390/app11020472},
	abstract = {Machine learning has been proven to be effective in various application areas, such as object and speech recognition on mobile systems. Since a critical key to machine learning success is the availability of large training data, many datasets are being disclosed and published online. From a data consumer or manager point of view, measuring data quality is an important first step in the learning process. We need to determine which datasets to use, update, and maintain. However, not many practical ways to measure data quality are available today, especially when it comes to large-scale high-dimensional data, such as images and videos. This paper proposes two data quality measures that can compute class separability and in-class variability, the two important aspects of data quality, for a given dataset. Classical data quality measures tend to focus only on class separability; however, we suggest that in-class variability is another important data quality factor. We provide efficient algorithms to compute our quality measures based on random projections and bootstrapping with statistical benefits on large-scale high-dimensional data. In experiments, we show that our measures are compatible with classical measures on small-scale data and can be computed much more efficiently on large-scale high-dimensional datasets.},
	language = {en},
	number = {2},
	urldate = {2024-05-22},
	journal = {Applied Sciences},
	author = {Cho, Hyeongmin and Lee, Sangkyun},
	month = jan,
	year = {2021},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {bootstrapping, data quality, high-dimensionality, large-scale, linear discriminant analysis, random projection},
	pages = {472},
}

@inproceedings{chen2022,
	location = {Singapore},
	title = {Measuring Difficulty of Learning Using Ensemble Methods},
	isbn = {978-981-19874-6-5},
	doi = {10.1007/978-981-19-8746-5_3},
	abstract = {Measuring the difficulty of each instance is a crucial meta-knowledge extraction problem. Most studies on data complexity have focused on extracting the characteristics at a dataset level instead of the instance level while also requiring the complete label knowledge of the dataset, which can often be expensive to obtain. At the instance level, the most commonly used metrics to determine difficult to classify instances are dependant on the learning algorithm used (i.e., uncertainty), and are measurements of the entire system instead of only the dataset. Additionally, these metrics only provide information of misclassification in regard to the learning algorithm and not in respect of the composition of the instances within the dataset. We introduce and propose several novel instance difficulty measures in a semi-supervised boosted ensemble setting to identify difficult to classify instances based on their learning difficulty in relation to other instances within the dataset. The proposed difficulty measures measure both the fluctuations in labeling during the construction process of the ensemble and the amount of resources required for the correct label. This provides the degree of difficulty and gives further insight into the origin of classification difficulty at the instance level reflected by the scores of different difficulty measures.},
	pages = {28--42},
	booktitle = {Data Mining},
	publisher = {Springer Nature},
	author = {Chen, Bowen and Koh, Yun Sing and Halstead, Ben},
	editor = {Park, Laurence A. F. and Gomes, Heitor Murilo and Doborjeh, Maryam and Boo, Yee Ling and Koh, Yun Sing and Zhao, Yanchang and Williams, Graham and Simoff, Simeon},
	year = {2022},
	langid = {english},
}

@article{ivanovici2020,
	title = {Color {Image} {Complexity} versus {Over}-{Segmentation}: {A} {Preliminary} {Study} on the {Correlation} between {Complexity} {Measures} and {Number} of {Segments}},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2313-433X},
	shorttitle = {Color {Image} {Complexity} versus {Over}-{Segmentation}},
	url = {https://www.mdpi.com/2313-433X/6/4/16},
	doi = {10.3390/jimaging6040016},
	abstract = {It is said that image segmentation is a very difficult or complex task. First of all, we emphasize the subtle difference between the notions of difficulty and complexity. Then, in this article, we focus on the question of how two widely used color image complexity measures correlate with the number of segments resulting in over-segmentation. We study the evolution of both the image complexity measures and number of segments as the image complexity is gradually decreased by means of low-pass filtering. In this way, we tackle the possibility of predicting the difficulty of color image segmentation based on image complexity measures. We analyze the complexity of images from the point of view of color entropy and color fractal dimension and for color fractal images and the Berkeley data set we correlate these two metrics with the segmentation results, more specifically the number of quasi-flat zones and the number of JSEG regions in the resulting segmentation map. We report on our experimental results and draw conclusions.},
	language = {en},
	number = {4},
	urldate = {2024-05-22},
	journal = {Journal of Imaging},
	author = {Ivanovici, Mihai and Coliban, Radu-Mihai and Hatfaludi, Cosmin and Nicolae, Irina Emilia},
	month = apr,
	year = {2020},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {JSEG, color entropy, color fractal dimension, image complexity, quasi-flat zones},
	pages = {16},
}


@article{chinn_enriching_2023,
	title = {{ENRICHing} medical imaging training sets enables more efficient machine learning},
	volume = {30},
    year = {2023},
    journal = {J Am Med Inform Assoc},
	issn = {1527-974X},
	doi = {10.1093/jamia/ocad055},
	abstract = {{OBJECTIVE}: Deep learning ({DL}) has been applied in proofs of concept across biomedical imaging, including across modalities and medical specialties. Labeled data are critical to training and testing {DL} models, but human expert labelers are limited. In addition, {DL} traditionally requires copious training data, which is computationally expensive to process and iterate over. Consequently, it is useful to prioritize using those images that are most likely to improve a model's performance, a practice known as instance selection. The challenge is determining how best to prioritize. It is natural to prefer straightforward, robust, quantitative metrics as the basis for prioritization for instance selection. However, in current practice, such metrics are not tailored to, and almost never used for, image datasets.
{MATERIALS} {AND} {METHODS}: To address this problem, we introduce {ENRICH}-Eliminate Noise and Redundancy for Imaging Challenges-a customizable method that prioritizes images based on how much diversity each image adds to the training set.
{RESULTS}: First, we show that medical datasets are special in that in general each image adds less diversity than in nonmedical datasets. Next, we demonstrate that {ENRICH} achieves nearly maximal performance on classification and segmentation tasks on several medical image datasets using only a fraction of the available images and without up-front data labeling. {ENRICH} outperforms random image selection, the negative control. Finally, we show that {ENRICH} can also be used to identify errors and outliers in imaging datasets.
{CONCLUSIONS}: {ENRICH} is a simple, computationally efficient method for prioritizing images for expert labeling and use in {DL}.},
	pages = {1079--1090},
	number = {6},
	journaltitle = {Journal of the American Medical Informatics Association: {JAMIA}},
	shortjournal = {J Am Med Inform Assoc},
	author = {Chinn, Erin and Arora, Rohit and Arnaout, Ramy and Arnaout, Rima},
	date = {2023-05-19},
	pmid = {37036945},
	pmcid = {PMC10198519},
	keywords = {data efficiency, data quality, deep learning, Diagnostic Imaging, Humans, Image Processing, Computer-Assisted, information theory, instance selection, Machine Learning, medical imaging, Palliative Care, Radiography},
	file = {Full Text:C\:\\Users\\Kenny\\Zotero\\storage\\96HEHN7G\\Chinn et al. - 2023 - ENRICHing medical imaging training sets enables mo.pdf:application/pdf},
}

@article{dey_proceedings_2023,
	title = {Proceedings of the {NHLBI} Workshop on Artificial Intelligence in Cardiovascular Imaging: Translation to Patient Care},
	volume = {16},
	issn = {1876-7591},
	doi = {10.1016/j.jcmg.2023.05.012},
	shorttitle = {Proceedings of the {NHLBI} Workshop on Artificial Intelligence in Cardiovascular Imaging},
	abstract = {Artificial intelligence ({AI}) promises to revolutionize many fields, but its clinical implementation in cardiovascular imaging is still rare despite increasing research. We sought to facilitate discussion across several fields and across the lifecycle of research, development, validation, and implementation to identify challenges and opportunities to further translation of {AI} in cardiovascular imaging. Furthermore, it seemed apparent that a multidisciplinary effort across institutions would be essential to overcome these challenges. This paper summarizes the proceedings of the National Heart, Lung, and Blood Institute-led workshop, creating consensus around needs and opportunities for institutions at several levels to support and advance research in this field and support future translation.},
	pages = {1209--1223},
	number = {9},
    journal={{JACC} Cardiovasc Imaging},
    year={2023},
	journaltitle = {{JACC}. Cardiovascular imaging},
	shortjournal = {{JACC} Cardiovasc Imaging},
	author = {Dey, Damini and Arnaout, Rima and Antani, Sameer and Badano, Aldo and Jacques, Louis and Li, Huiqing and Leiner, Tim and Margerrison, Edward and Samala, Ravi and Sengupta, Partho P. and Shah, Sanjiv J. and Slomka, Piotr and Williams, Michelle C. and Bandettini, W. Patricia and Sachdev, Vandana},
	date = {2023-09},
	pmid = {37480904},
	pmcid = {PMC10524663},
	keywords = {{AI} algorithms, artificial intelligence, Artificial Intelligence, cardiovascular imaging, Cardiovascular System, data science, deep learning, Humans, machine learning, National Heart, Lung, and Blood Institute (U.S.), Patient Care, Predictive Value of Tests, United States},
}

@online{miao_minimum_2024,
	title = {The Minimum Information about {CLinical} Artificial Intelligence Checklist for Generative Modeling Research ({MI}-{CLAIM}-{GEN})},
	url = {https://arxiv.org/abs/2403.02558v2},
	abstract = {Recent advances in generative models, including large language models ({LLMs}), vision language models ({VLMs}), and diffusion models, have accelerated the field of natural language and image processing in medicine and marked a significant paradigm shift in how biomedical models can be developed and deployed. While these models are highly adaptable to new tasks, scaling and evaluating their usage presents new challenges not addressed in previous frameworks. In particular, the ability of these models to produce useful outputs with little to no specialized training data ("zero-" or "few-shot" approaches), as well as the open-ended nature of their outputs, necessitate the development of new guidelines for robust reporting of clinical generative model research. In response to gaps in standards and best practices for the development of clinical {AI} tools identified by {US} Executive Order 141103 and several emerging national networks for clinical {AI} evaluation, we begin to formalize some of these guidelines by building on the original {MI}-{CLAIM} checklist. The new checklist, {MI}-{CLAIM}-{GEN} (Table 1), aims to address differences in training, evaluation, interpretability, and reproducibility of new generative models compared to non-generative ("predictive") {AI} models. This {MI}-{CLAIM}-{GEN} checklist also seeks to clarify cohort selection reporting with unstructured clinical data and adds additional items on alignment with ethical standards for clinical {AI} research.},
	titleaddon = {{arXiv}.org},
	author = {Miao, Brenda Y. and Chen, Irene Y. and Williams, Christopher {YK} and Davidson, Jaysón and Garcia-Agundez, Augusto and Sun, Shenghuan and Zack, Travis and Saria, Suchi and Arnaout, Rima and Quer, Giorgio and Sadaei, Hossein J. and Torkamani, Ali and Beaulieu-Jones, Brett and Yu, Bin and Gianfrancesco, Milena and Butte, Atul J. and Norgeot, Beau and Sushil, Madhumita},
	urldate = {2024-10-07},
	date = {2024-03-05},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\Kenny\\Zotero\\storage\\WAZVCZFR\\Miao et al. - 2024 - The Minimum Information about CLinical Artificial .pdf:application/pdf},
}

@article{athalye_deep-learning_2024,
	title = {Deep-learning model for prenatal congenital heart disease screening generalizes to community setting and outperforms clinical detection},
	volume = {63},
	issn = {1469-0705},
	doi = {10.1002/uog.27503},
	abstract = {{OBJECTIVES}: Despite nearly universal prenatal ultrasound screening programs, congenital heart defects ({CHD}) are still missed, which may result in severe morbidity or even death. Deep machine learning ({DL}) can automate image recognition from ultrasound. The main aim of this study was to assess the performance of a previously developed {DL} model, trained on images from a tertiary center, using fetal ultrasound images obtained during the second-trimester standard anomaly scan in a low-risk population. A secondary aim was to compare initial screening diagnosis, which made use of live imaging at the point-of-care, with diagnosis by clinicians evaluating only stored images.
{METHODS}: All pregnancies with isolated severe {CHD} in the Northwestern region of The Netherlands between 2015 and 2016 with available stored images were evaluated, as well as a sample of normal fetuses' examinations from the same region and time period. We compared the accuracy of the initial clinical diagnosis (made in real time with access to live imaging) with that of the model (which had only stored imaging available) and with the performance of three blinded human experts who had access only to the stored images (like the model). We analyzed performance according to ultrasound study characteristics, such as duration and quality (scored independently by investigators), number of stored images and availability of screening views.
{RESULTS}: A total of 42 normal fetuses and 66 cases of isolated {CHD} at birth were analyzed. Of the abnormal cases, 31 were missed and 35 were detected at the time of the clinical anatomy scan (sensitivity, 53\%). Model sensitivity and specificity were 91\% and 78\%, respectively. Blinded human experts (n = 3) achieved mean ± {SD} sensitivity and specificity of 55 ± 10\% (range, 47-67\%) and 71 ± 13\% (range, 57-83\%), respectively. There was a statistically significant difference in model correctness according to expert-graded image quality (P = 0.03). The abnormal cases included 19 lesions that the model had not encountered during its training; the model's performance in these cases (16/19 correct) was not statistically significantly different from that for previously encountered lesions (P = 0.41).
{CONCLUSIONS}: A previously trained {DL} algorithm had higher sensitivity than initial clinical assessment in detecting {CHD} in a cohort in which over 50\% of {CHD} cases were initially missed clinically. Notably, the {DL} algorithm performed well on community-acquired images in a low-risk population, including lesions to which it had not been exposed previously. Furthermore, when both the model and blinded human experts had access to only stored images and not the full range of images available to a clinician during a live scan, the model outperformed the human experts. Together, these findings support the proposition that use of {DL} models can improve prenatal detection of {CHD}. © 2023 International Society of Ultrasound in Obstetrics and Gynecology.},
	pages = {44--52},
	number = {1},
	journaltitle = {Ultrasound in Obstetrics \& Gynecology: The Official Journal of the International Society of Ultrasound in Obstetrics and Gynecology},
	shortjournal = {Ultrasound Obstet Gynecol},
	author = {Athalye, C. and van Nisselrooij, A. and Rizvi, S. and Haak, M. C. and Moon-Grady, A. J. and Arnaout, R.},
	date = {2024-01},
	pmid = {37774040},
	pmcid = {PMC10841849},
	keywords = {artificial intelligence, congenital heart disease, Deep Learning, Female, fetal screening, Heart Defects, Congenital, Humans, Infant, Newborn, machine learning, Pregnancy, Prenatal Diagnosis, Sensitivity and Specificity, Ultrasonography, Prenatal, ultrasound},
}

@online{ferreira_label-free_2022,
	title = {Label-free segmentation from cardiac ultrasound using self-supervised learning},
	url = {https://arxiv.org/abs/2210.04979v2},
	abstract = {Segmentation and measurement of cardiac chambers is critical in cardiac ultrasound but is laborious and poorly reproducible. Neural networks can assist, but supervised approaches require the same laborious manual annotations. We built a pipeline for self-supervised (no manual labels) segmentation combining computer vision, clinical domain knowledge, and deep learning. We trained on 450 echocardiograms (93,000 images) and tested on 8,393 echocardiograms (4,476,266 images; mean 61 years, 51\% female), using the resulting segmentations to calculate biometrics. We also tested against external images from an additional 10,030 patients with available manual tracings of the left ventricle. r2 between clinically measured and pipeline-predicted measurements were similar to reported inter-clinician variation and comparable to supervised learning across several different measurements (r2 0.56-0.84). Average accuracy for detecting abnormal chamber size and function was 0.85 (range 0.71-0.97) compared to clinical measurements. A subset of test echocardiograms (n=553) had corresponding cardiac {MRIs}, where {MRI} is the gold standard. Correlation between pipeline and {MRI} measurements was similar to that between clinical echocardiogram and {MRI}. Finally, the pipeline accurately segments the left ventricle with an average Dice score of 0.89 (95\% {CI} [0.89]) in the external, manually labeled dataset. Our results demonstrate a manual-label free, clinically valid, and highly scalable method for segmentation from ultrasound, a noisy but globally important imaging modality.},
	titleaddon = {{arXiv}.org},
	author = {Ferreira, Danielle L. and Salaymang, Zaynaf and Arnaout, Rima},
	urldate = {2024-10-07},
	date = {2022-10-10},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\Kenny\\Zotero\\storage\\9KFHM3UX\\Ferreira et al. - 2022 - Label-free segmentation from cardiac ultrasound us.pdf:application/pdf},
}

@inproceedings{51055,title	= {Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research},author	= {Bernard Koch and Emily Denton and Alex Hanna and Jacob Foster},year	= {2021},booktitle={None}}

@INPROCEEDINGS{8317828,
  author={Yin, Hang and Berger, Christian},
  booktitle={2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={When to use what data set for your self-driving car algorithm: An overview of publicly available driving datasets}, 
  year={2017},
  volume={},
  number={},
  pages={1-8},
  keywords={Sensors;Data collection;Roads;Web pages;Benchmark testing;Laser radar;Cameras},
  doi={10.1109/ITSC.2017.8317828}}

@article{MAYFIELD201717,
title = {Use of freely available datasets and machine learning methods in predicting deforestation},
journal = {Environmental Modelling \& Software},
volume = {87},
pages = {17-28},
year = {2017},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2016.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364815216308428},
author = {Helen Mayfield and Carl Smith and Marcus Gallagher and Marc Hockings},
keywords = {Artificial neural network, Bayesian network, Deforestation, Freely available data, Gaussian process, Logistic regression},
abstract = {The range and quality of freely available geo-referenced datasets is increasing. We evaluate the usefulness of free datasets for deforestation prediction by comparing generalised linear models and generalised linear mixed models (GLMMs) with a variety of machine learning models (Bayesian networks, artificial neural networks and Gaussian processes) across two study regions. Freely available datasets were able to generate plausible risk maps of deforestation using all techniques for study zones in both Mexico and Madagascar. Artificial neural networks outperformed GLMMs in the Madagascan (average AUC 0.83 vs 0.80), but not the Mexican study zone (average AUC 0.81 vs 0.89). In Mexico and Madagascar, Gaussian processes (average AUC 0.89, 0.85) and structured Bayesian networks (average AUC 0.88, 0.82) performed at least as well as GLMMs (average AUC 0.89, 0.80). Bayesian networks produced more stable results across different sampling methods. Gaussian processes performed well (average AUC 0.85) with fewer predictor variables.}
}


@inproceedings{bicer_koios_2011,
	address = {Berlin, Heidelberg},
	title = {{KOIOS}: {Utilizing} {Semantic} {Search} for {Easy}-{Access} and {Visualization} of {Structured} {Environmental} {Data}},
	isbn = {978-3-642-25093-4},
	abstract = {With the increasing interest in environmental issues, the amount of publicly available environmental data on the Web is continuously growing. Despite its importance, the uptake of environmental information by the ordinary Web users is still very limited due to intransparent access to complex and distributed databases. As a remedy to this problem, in this work, we propose the use of semantic search technologies recently developed as an intuitive way to easily access structured data and lower the barriers to obtain information satisfying user information needs. Our proposed system, namely KOIOS, enables a simple, keyword-based search on structured environmental data and built on top of a commercial Environmental Information System (EIS). A prototype system successfully shows that applying semantic search techniques this way provides intuitive means for search and access to complex environmental information.},
	booktitle = {The {Semantic} {Web} – {ISWC} 2011},
	publisher = {Springer Berlin Heidelberg},
	author = {Bicer, Veli and Tran, Thanh and Abecker, Andreas and Nedkov, Radoslav},
	editor = {Aroyo, Lora and Welty, Chris and Alani, Harith and Taylor, Jamie and Bernstein, Abraham and Kagal, Lalana and Noy, Natasha and Blomqvist, Eva},
	year = {2011},
	pages = {1--16},
}

@article{52002,title	= {Are we cobblers without shoes? Making Computer Science data FAIR},author	= {Natasha Noy and Carole Goble},year	= {2023},URL	= {https://cacm.acm.org/magazines/2023/1/267975-are-we-cobblers-without-shoes/abstract},journal	= {Communications of ACM},volume	= {66 (1)}}


@article{yoong_benefits_2022,
	title = {The benefits of data sharing and ensuring open sources of systematic review data},
	volume = {44},
	issn = {1741-3842},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9715297/},
	doi = {10.1093/pubmed/fdac031},
	abstract = {Aims
The benefits of increasing public access to data from clinical trials are widely accepted. Such benefits extend to the sharing of data from high-quality systematic reviews, given the time and cost involved with undertaking reviews. We describe the application of open sources of review data, outline potential challenges and highlight efforts made to address these challenges, with the intent of encouraging publishers, funders and authors to consider sharing review data more broadly.

Results
We describe the application of systematic review data in: (i) advancing understanding of clinical trials and systematic review methods, (ii) repurposing of data to answer public health policy and practice relevant questions, (iii) identification of research gaps and (iv) accelerating the conduct of rapid reviews to inform decision making. While access, logistical, motivational and legal challenges exist, there has been progress made by systematic review, academic and funding agencies to incentivise data sharing and create infrastructure to support greater access to systematic review data.

Conclusion
There is opportunity to maximize the benefits of research investment in undertaking systematic reviews by ensuring open sources of systematic review data. Efforts to create such systems should draw on learnings and principles outlined for sharing clinical trial data.},
	number = {4},
	urldate = {2024-10-08},
	journal = {Journal of Public Health (Oxford, England)},
	author = {Yoong, Sze Lin and Turon, Heidi and Grady, Alice and Hodder, Rebecca and Wolfenden, Luke},
	month = mar,
	year = {2022},
	pmid = {35285884},
	pmcid = {PMC9715297},
	pages = {e582--e587},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Kenny\\Zotero\\storage\\AUY9GFDK\\Yoong et al. - 2022 - The benefits of data sharing and ensuring open sou.pdf:application/pdf},
}
